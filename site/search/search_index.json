{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Inuyasha\u7684\u6280\u672f\u535a\u5ba2","text":"<p>\u8fd9\u91cc\u662fInuyasha\u7684\u6280\u672f\u535a\u5ba2\uff0c\u7528\u6765\u8bb0\u5f55\u4e0e\u5206\u4eabLLM\u7b97\u6cd5&amp;\u5e94\u7528\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u5de5\u7a0b\u95ee\u9898\u548c\u6280\u672f\u65b9\u6848</p>"},{"location":"eval_agent/","title":"Eval Agent","text":"LLM\u89e3\u9898 <pre><code>prompt_template = '''\n\u8bf7\u4ed4\u7ec6\u9605\u8bfb\u4ee5\u4e0b\u6570\u5b66\u95ee\u9898\uff0c\u5e76\u6309\u7167\u6b65\u9aa4\u8fdb\u884c\u601d\u8003\u548c\u89e3\u7b54\uff1a\n\n\u95ee\u9898\uff1a{pos1}\n\n\u8bf7\u6309\u7167\u4ee5\u4e0b\u6b65\u9aa4\u8fdb\u884c\u601d\u8003\uff1a\n\n1. \u7406\u89e3\u95ee\u9898\uff1a\n   - \u4ed4\u7ec6\u9605\u8bfb\u9898\u76ee\uff0c\u786e\u5b9a\u5df2\u77e5\u6761\u4ef6\u548c\u9700\u8981\u8bc1\u660e\u6216\u8ba1\u7b97\u7684\u5185\u5bb9\u3002\n   - \u8bc6\u522b\u9898\u76ee\u4e2d\u7684\u5173\u952e\u6570\u5b66\u6982\u5ff5\u548c\u7b26\u53f7\u3002\n\n2. \u5206\u6790\u95ee\u9898\uff1a\n   - \u8003\u8651\u53ef\u80fd\u9002\u7528\u4e8e\u8fd9\u4e2a\u95ee\u9898\u7684\u6570\u5b66\u5b9a\u7406\u6216\u516c\u5f0f\u3002\n   - \u601d\u8003\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u53ef\u80fd\u9700\u8981\u7684\u6570\u5b66\u6280\u5de7\u6216\u65b9\u6cd5\u3002\n\n3. \u5236\u5b9a\u89e3\u9898\u7b56\u7565\uff1a\n   - \u6839\u636e\u95ee\u9898\u7684\u6027\u8d28\uff0c\u51b3\u5b9a\u4f7f\u7528\u76f4\u63a5\u8bc1\u660e\u3001\u53cd\u8bc1\u6cd5\u3001\u6570\u5b66\u5f52\u7eb3\u6cd5\u7b49\u65b9\u6cd5\u3002\n   - \u5982\u679c\u662f\u8ba1\u7b97\u95ee\u9898\uff0c\u8003\u8651\u6700\u9002\u5408\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002\n\n4. \u9010\u6b65\u89e3\u7b54\uff1a\n   - \u6309\u7167\u903b\u8f91\u987a\u5e8f\uff0c\u4e00\u6b65\u4e00\u6b65\u5730\u63a8\u5bfc\u6216\u8ba1\u7b97\u3002\n   - \u786e\u4fdd\u6bcf\u4e00\u6b65\u90fd\u6709\u6e05\u6670\u7684\u7406\u7531\u548c\u4f9d\u636e\u3002\n\n5. \u68c0\u67e5\u7ed3\u679c\uff1a\n   - \u9a8c\u8bc1\u4f60\u7684\u89e3\u7b54\u662f\u5426\u6ee1\u8db3\u9898\u76ee\u7684\u6240\u6709\u6761\u4ef6\u3002\n   - \u68c0\u67e5\u8ba1\u7b97\u548c\u63a8\u7406\u8fc7\u7a0b\u662f\u5426\u5b58\u5728\u9519\u8bef\u3002\n\n6. \u603b\u7ed3\u7b54\u6848\uff1a\n   - \u7b80\u660e\u627c\u8981\u5730\u603b\u7ed3\u6700\u7ec8\u7684\u7ed3\u8bba\u6216\u7b54\u6848\u3002\n\n\u8bf7\u5728\u5b8c\u6210\u4ee5\u4e0a\u601d\u8003\u6b65\u9aa4\u540e\uff0c\u4f7f\u7528\u4e0b\u9762\u7684\u6a21\u677f\u683c\u5f0f\u63d0\u4f9b\u4f60\u7684\u6700\u7ec8\u7b54\u6848\uff1a\n\n{data_template}\n\n\u6ce8\u610f\uff1a\u53ea\u9700\u5728\u7b54\u6848\u90e8\u5206\u586b\u5199\u4f60\u7684\u6700\u7ec8\u7ed3\u8bba\u6216\u8ba1\u7b97\u7ed3\u679c\uff0c\u4e0d\u9700\u8981\u5305\u542b\u8be6\u7ec6\u7684\u89e3\u9898\u8fc7\u7a0b\u3002\u8bf7\u786e\u4fdd\u4f60\u7684\u7b54\u6848\u7b80\u6d01\u660e\u4e86\uff0c\u76f4\u63a5\u56de\u7b54\u95ee\u9898\u7684\u6838\u5fc3\u5185\u5bb9\u3002\n'''\n\ndata_template='''\n\u6211\u4eec\u8981\u6c42\u4f60\u5fc5\u987b\u4f7f\u7528=start_pad=\u548c=end_pad=\u6765\u5305\u88f9\u4f60\u6700\u7ec8\u7684\u7b54\u6848\uff0c\u5373\u5982\u4e0b\u5f62\u5f0f\n\n    =start_pad= .... =end_pad=\n'''\n</code></pre> <pre><code>pos1 input_mathematical_problem\n</code></pre> \u7b54\u6848\u6b63\u786e\u6027\u5224\u65ad <pre><code>prompt_template = '''\n\u4f60\u662f\u4e00\u4e2a\u51c6\u786e\u7684\u5224\u5377\u8005\n\u5b66\u751f\u7684\u7b54\u6848\u662f {pos1} \n\n\u6807\u51c6\u7b54\u6848\u662f {pos2}\n\n\u8bf7\u4f60\u6307\u51fa\u4e24\u8005\u662f\u5426\u4e00\u81f4\uff0c\u4ee5{pos2}\u4e3a\u51c6\n\n\u76f4\u63a5\u4ee5\u5982\u4e0b\u683c\u5f0f\u8fd4\u56de\uff0c\u65e0\u9700\u89e3\u91ca\n\n{data_template}\n\n\u5982\u6b63\u786e\uff0c\u5199True\uff0c\u5982\u9519\u8bef\uff0c\u5199False\uff0c\u5982\u6beb\u4e0d\u76f8\u5173\u6216\u80e1\u8a00\u4e71\u8bed\uff0c\u4e5f\u5199False\n'''\n\ndata_template='''\n{'Res':True/False}\n'''\n</code></pre> <pre><code>pos1 student_answer\npos2 standard_answer\n</code></pre>"},{"location":"lean_agent/","title":"1. \u5404\u4e2a\u5904\u7406\u73af\u8282\u7684\u63d0\u793a\u8bcd\u6574\u7406","text":""},{"location":"lean_agent/#11","title":"1.1 \u91c7\u6837\u4e0e\u751f\u6210","text":"\u751f\u6210\u6570\u5b66\u5b66\u79d1\u6811 <pre><code>prompt = f'''As a mathematics expert, focus exclusively on generating precise and specific subfields within pure and applied mathematics for the field of \"{node_name}\". \nConsider the following context: {node_field_info}\n\nGuidelines:\n1. Provide 3-5 direct subfields that are strictly within mathematics.\n2. Ensure each subfield is more specific and narrower than \"{node_name}\".\n3. Avoid any cross-disciplinary fields or applications outside of mathematics.\n4. Focus on established mathematical concepts, not speculative or emerging ideas.\n5. If a subfield seems too broad, break it down further into more specific areas.\n\nRespond strictly in the following JSON format:\n{data_template}\n\nEnsure each subfield name is concise yet descriptive, using standard mathematical terminology.'''\n\ndata_template = \"{'child1': 'subfield_name1', 'child2': 'subfield_name2', ...}\"\n</code></pre> <pre><code>- node_name:\u5f53\u524d\u6570\u5b66\u9886\u57df\u8282\u70b9\u540d\u79f0\n- node_field_info:\u5f53\u524d\u6570\u5b66\u9886\u57df\u7684\u76f8\u5173\u4fe1\u606f\n</code></pre> \u81ea\u7136\u8bed\u8a00\u547d\u9898\u751f\u6210\u6bcd\u7248 <pre><code>prompt_meta_template = '''\nPlease generate a random mathematical statement or theorem expressed in natural language. This statement or theorem should come from the following mathematical fields:\n\n{math_field}\n\nPlease express it in clear, easy-to-understand natural language, avoiding excessive use of mathematical symbols. The generated content can be a basic concept or a more advanced theorem. Ensure that the statement is clear and comprehensible.\n\nPlease output this randomly generated mathematical statement in the following format:\n\n{data_template}\n'''\n</code></pre> <pre><code>math_field input_mathematical_fields\ndata_template output_format_template\n</code></pre> \u81ea\u7136\u8bed\u8a00\u7ffb\u8bd1\u4e3aLean4 <pre><code>prompt_template02 = '''\nGiven the natural language math statement {pos1}, translate it into Lean 4 theorem syntax. Please follow this data template:\n\n{data_template}\n\nOnly provide the theorem statement without the proof. Use the appropriate Unicode symbols for mathematical notation where applicable.\n\nExamples:\n\n1. Natural language: If $r$ is rational $(r \\neq 0)$ and $x$ is irrational, prove that $r+x$ is irrational.\n   {{\"lean_statement\": \"theorem exercise_1_1a (x : \u211d) (y : \u211a) : (irrational x) -&gt; irrational (x + y) :=\"}}\n\n2. Natural language: Prove that there is no rational number whose square is $12$.\n   {{\"lean_statement\": \"theorem exercise_1_2 : \u00ac \u2203 (x : \u211a), (x ^ 2 = 12) :=\"}}\n\n3. Natural language: Let $A$ be a nonempty set of real numbers which is bounded below. Let $-A$ be the set of all numbers $-x$, where $x \\in A$. Prove that $\\inf A=-\\sup (-A)$.\n   {{\"lean_statement\": \"theorem exercise_1_5 (A minus_A : set \u211d) (hA : A.nonempty) (hA_bdd_below : bdd_below A) (hminus_A : minus_A = {{x | -x \u2208 A}}) : Inf A = Sup minus_A :=\"}}\n\n4. Natural language: If $z$ is a complex number, prove that there exists an $r\\geq 0$ and a complex number $w$ with $| w | = 1$ such that $z = rw$.\n   {{\"lean_statement\": \"theorem exercise_1_11a (z : \u2102) : \u2203 (r : \u211d) (w : \u2102), abs w = 1 \u2227 z = r * w :=\"}}\n################################################################\nNow, please translate the following statement into Lean 4:\n\n{pos1}\n'''\n\ndata_template02='''\n    {\"lean_statement\":translated_lean_statement_str_here}\n'''\n</code></pre> <pre><code>pos1:input_natural_language_statement\n</code></pre> Lean\u8bed\u53e5\u7ffb\u8bd1\u4e3a\u81ea\u7136\u8bed\u8a00 <pre><code>prompt_template ='''\n    Here is a Lean statement: {pos1}.\n    I want you to translate it into natural language and output it in the following format:\n    {data_template}\n'''\n\ndata_template='''\n    {\"lean\":lean_str_here,\"natural_language\":nl_translation_here}\n'''\n</code></pre> <pre><code>pos1:input_lean_statement\n</code></pre>"},{"location":"lean_agent/#12","title":"1.2 \u540e\u5904\u7406\u9636\u6bb5","text":"Lean-NL\u547d\u9898\u5bf9\u5b66\u79d1\u5f52\u7c7b <pre><code>prompt_template = '''\n\u6211\u4eec\u8bd5\u56fe\u91cd\u6784\u4e00\u4e2a\u7531lean4\u5f62\u5f0f\u5316\u8bed\u53e5\u548c\u81ea\u7136\u8bed\u53e5\u6240\u5171\u540c\u8868\u8ff0\u7684\u6570\u5b66\u547d\u9898\u7684\u6570\u5b66\u9886\u57df\u7ed3\u6784\uff0c\u4f60\u9700\u8981\u7ed9\u6211\u8fd9\u4e2a\u6570\u5b66\u547d\u9898\u7684\u5c42\u7ea7\u548c\u5177\u4f53\u7684\u8def\u5f84\n\u6211\u4eec\u63d0\u4f9b\u4e0b\u9762\u7684\u4e00\u4e9b\u4f8b\u5b50\n  \u5047\u5982\u5bf9\u8c61\u88ab\u5f52\u5165\"Mathematics / Number Theory / Diophantine Equations / Higher-Degree Diophantine Equations / Quintic Diophantine Equations / Quintic Diophantine Equations with Rational Coefficients / Symmetry and Group Theory in Quintic Diophantine Equations with Rational Coefficients\",\n    \u4ed6\u662f\u4e00\u4e2a6\u5c42\u7ed3\u6784\uff0c\u56e0\u4e3a\u4ed6\u4eceMathematics\u7684\u8282\u70b9\u5f80\u4e0b\u6cbf\u751f\u4e866\u5c42\uff0c\n    \u6837\u4f8b\u8f93\u51fa\uff1a{{\"math_depth\": 6,\n    \"math_field_path\":\"Mathematics / Number Theory / Diophantine Equations / Higher-Degree Diophantine Equations / Quintic Diophantine Equations / Quintic Diophantine Equations with Rational Coefficients / Symmetry and Group Theory in Quintic Diophantine Equations with Rational Coefficients\"}}\n    \u5047\u5982\u5bf9\u8c61\u88ab\u5f52\u5165\"Mathematics / Combinatorics / Graph Theory / Graph Decompositions / Star Decompositions\"\n    \u90a3\u4e48\u5176\u6df1\u5ea6\u4e3a4\n    \u6837\u4f8b\u8f93\u51fa\uff1a{{\"math_depth\": 4,\n    \"math_field_path\":\"Mathematics / Combinatorics / Graph Theory / Graph Decompositions / Star Decompositions\"}}\n####################################################\n   \u73b0\u5728\u8bf7\u4f60\u5ffd\u7565\u4ee5\u4e0a\u7684\u793a\u4f8b\u7684\u5185\u5bb9:\n   {data_template}\n   \u751f\u6210\u4ee5\u4e0b\u547d\u9898\u7684\u5206\u6790\n   lean4\u683c\u5f0f\uff1a{pos1}\n   \u81ea\u7136\u8bed\u8a00\u683c\u5f0f:{pos2}\n'''\n\ndata_template='''\n    {\"math_depth\": math_depth_int,\n    \"math_field_path\":field_path_str}\n'''\n</code></pre> <pre><code>pos1 input_lean_statement \n\npos2 input_natural_language_statement \n</code></pre> Lean-NL\u547d\u9898\u7684\u5b50\u547d\u9898\u786e\u5b9a <pre><code>prompt_template = '''\n\u6211\u4eec\u6b63\u5728\u6df1\u5165\u7814\u7a76\u6570\u5b66\u547d\u9898\u7684\u5f62\u5f0f\u5316\u8868\u8ff0\u3002\u6211\u4f1a\u7ed9\u4f60\u4e00\u4e2a\u6570\u5b66\u547d\u9898\uff0c\u5305\u62ec\u5b83\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548cLean4\u5f62\u5f0f\u5316\u8868\u8ff0\u3002\u4f60\u7684\u4efb\u52a1\u662f\u8bc6\u522b\u5e76\u5f62\u5f0f\u5316\u8fd9\u4e2a\u547d\u9898\u76f4\u63a5\u4f9d\u8d56\u7684\u5b50\u547d\u9898\u6216\u57fa\u7840\u6982\u5ff5\u3002\n\n\u8bf7\u6309\u7167\u4ee5\u4e0b\u683c\u5f0f\u63d0\u4f9b\u4f60\u7684\u5206\u6790\uff1a\n\n{data_template}\n\n\u6ce8\u610f\uff0c\u6211\u4eec\u5f3a\u70c8\u8981\u6c42lean_str\u7684\u683c\u5f0f\u9075\u5faa\u7740:\nimport Mathlib\\nmain_content:=by sorry\n\u7684\u683c\u5f0f\u4ee5\u4fbf\u4e8e\u6211\u4eec\u4e4b\u540e\u7684\u9a8c\u8bc1\uff0c\u5982\u679c\u4ed6\u4e0d\u662f\u53ef\u4ee5\u63a5:=by sorry\u7684Lean4\u6982\u5ff5\uff0c\u4e5f\u8bf7\u4f60\u4f7f\u5176\u81ea\u6d3d\n\n\u4e0d\u8bb8\u63d0\u4f9bvariables \u4e0d\u9700\u8981\u989d\u5916\u7684\u89e3\u91ca\n\n\u73b0\u5728\uff0c\u8bf7\u5206\u6790\u4ee5\u4e0b\u547d\u9898\uff1a\n\nLean4\u5f62\u5f0f\u5316\uff1a\n{pos1}\n\n\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff1a\n{pos2}\n\n\u8bf7\u5b8c\u6210\u4ee5\u4e0b\u4efb\u52a1\uff1a\n1. \u8bc6\u522b\u8fd9\u4e2a\u547d\u9898\u76f4\u63a5\u4f9d\u8d56\u7684\u82e5\u5e72\u4e2a\u5173\u952e\u5b50\u547d\u9898\u6216\u57fa\u7840\u6982\u5ff5\u3002\n2. \u4e3a\u6bcf\u4e2a\u8bc6\u522b\u51fa\u7684\u5b50\u547d\u9898\u6216\u6982\u5ff5\u63d0\u4f9bLean4\u5f62\u5f0f\u5316\u8868\u8ff0\u3002\n3. \u7b80\u8981\u89e3\u91ca\u6bcf\u4e2a\u5b50\u547d\u9898\u6216\u6982\u5ff5\u4e0e\u4e3b\u547d\u9898\u7684\u5173\u7cfb\u3002\n4. \u5982\u679c\u53ef\u80fd\uff0c\u6307\u51fa\u8fd9\u4e9b\u5b50\u547d\u9898\u6216\u6982\u5ff5\u5728\u8bc1\u660e\u6216\u6784\u5efa\u4e3b\u547d\u9898\u65f6\u7684\u4f5c\u7528\u3002\n\n\u6ce8\u610f\uff1afocus\u5728\u76f4\u63a5\u76f8\u5173\u7684\u3001\u6784\u6210\u4e3b\u547d\u9898\u57fa\u7840\u7684\u5143\u7d20\u4e0a\uff0c\u800c\u4e0d\u662f\u66f4\u5e7f\u6cdb\u7684\u76f8\u5173\u6982\u5ff5\u3002\n'''\n\ndata_template='''\n    {\"statement_1\":{\"lean_statement\": lean_str,\n    \"natural_language_statement\":nl_str},...,\n    \"statement_n\":{\"lean_statement\": lean_str,\n    \"natural_language_statement\":nl_str}\n'''\n</code></pre> <pre><code>pos1 input_lean_statement\npos2 input_natural_language_description\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/","title":"Environment Setup","text":"<p>\u6211\u5e2e\u4f60\u5b8c\u5584\u548c\u91cd\u7ec4\u4e86\u8fd9\u4efd\u6307\u5357\uff1a</p>"},{"location":"DL_Engineering/Environment_Setup/#conda","title":"Conda \u73af\u5883\u7ba1\u7406\u6307\u5357","text":""},{"location":"DL_Engineering/Environment_Setup/#1","title":"1. \u73af\u5883\u7ba1\u7406\u57fa\u7840\u64cd\u4f5c","text":""},{"location":"DL_Engineering/Environment_Setup/#_1","title":"\u67e5\u770b\u73b0\u6709\u73af\u5883","text":"<pre><code>conda env list\n# \u6216\nconda info --envs\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/#_2","title":"\u521b\u5efa\u65b0\u73af\u5883","text":"<pre><code>conda create -n jy python=3.8\n</code></pre> <p>\u5efa\u8bae\u4f7f\u7528 Python 3.8 \u6216 3.9 \u7248\u672c</p>"},{"location":"DL_Engineering/Environment_Setup/#_3","title":"\u5220\u9664\u73af\u5883","text":"<pre><code># \u793a\u4f8b\uff1a\u5220\u9664\u6307\u5b9a\u73af\u5883\nconda env remove -n environment_name\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/#_4","title":"\u6fc0\u6d3b\u73af\u5883","text":"<pre><code>conda activate jy\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/#2","title":"2. \u73af\u5883\u914d\u7f6e\u6307\u5357","text":""},{"location":"DL_Engineering/Environment_Setup/#_5","title":"\u65b9\u6cd5\u4e00\uff1a\u5206\u6b65\u5b89\u88c5\uff08\u63a8\u8350\uff09","text":"<ol> <li>\u521b\u5efa\u5e76\u6fc0\u6d3b\u73af\u5883 <pre><code>conda create -n jy python=3.8.16\nconda activate jy\n</code></pre></li> <li>\u5b89\u88c5\u57fa\u7840\u79d1\u5b66\u8ba1\u7b97\u5305 <pre><code>conda install numpy pandas scipy matplotlib seaborn jupyter\n</code></pre></li> <li>\u5b89\u88c5\u673a\u5668\u5b66\u4e60\u548c\u6570\u636e\u5904\u7406\u5de5\u5177 <pre><code>conda install scikit-learn pillow opencv tqdm ipywidgets\n</code></pre></li> <li>\u5b89\u88c5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 <pre><code># PyTorch\uff08\u63a8\u8350\uff09\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n# \u6216 TensorFlow\nconda install tensorflow-gpu\n</code></pre></li> </ol>"},{"location":"DL_Engineering/Environment_Setup/#_6","title":"\u65b9\u6cd5\u4e8c\uff1a\u4e00\u6b21\u6027\u5b89\u88c5\u6240\u6709\u57fa\u7840\u5305","text":"<pre><code>conda install numpy pandas scipy matplotlib seaborn jupyter scikit-learn pillow opencv tqdm ipywidgets\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/#3","title":"3. \u73af\u5883\u5bfc\u51fa\u4e0e\u590d\u5236","text":""},{"location":"DL_Engineering/Environment_Setup/#_7","title":"\u5bfc\u51fa\u73af\u5883\u914d\u7f6e","text":"<pre><code># \u5bfc\u51fa\u4e3aYAML\u6587\u4ef6\uff08\u5305\u542b\u5b8c\u6574\u73af\u5883\u4fe1\u606f\uff09\nconda env export &gt; environment.yml\n\n# \u5bfc\u51fa\u4e3a\u7b80\u5355\u4f9d\u8d56\u5217\u8868\npip freeze &gt; requirements.txt\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/#_8","title":"\u4ece\u914d\u7f6e\u6587\u4ef6\u521b\u5efa\u73af\u5883","text":"<pre><code># \u4eceenvironment.yml\u521b\u5efa\u65b0\u73af\u5883\nconda env create -f environment.yml\n\n# \u66f4\u65b0\u73b0\u6709\u73af\u5883\nconda env update -f environment.yml\n</code></pre>"},{"location":"DL_Engineering/Environment_Setup/#_9","title":"\u6587\u4ef6\u4f4d\u7f6e\u8bf4\u660e","text":"<ul> <li>environment.yml \u9ed8\u8ba4\u521b\u5efa\u5728\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55</li> <li>conda\u73af\u5883\u901a\u5e38\u4f4d\u4e8eAnaconda\u5b89\u88c5\u76ee\u5f55\u4e0b</li> <li>\u53ef\u4ee5\u5728\u5bfc\u51fa\u65f6\u6307\u5b9a\u5b8c\u6574\u7684\u6587\u4ef6\u8def\u5f84</li> </ul>"},{"location":"DL_Engineering/Environment_Setup/#4","title":"4. \u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u4f18\u5148\u4f7f\u7528 conda \u800c\u975e pip \u8fdb\u884c\u5b89\u88c5</li> <li>\u5982\u679c conda \u5b89\u88c5\u5931\u8d25\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528 pip</li> <li>CUDA \u7248\u672c\u9700\u8981\u6839\u636e\u663e\u5361\u9a71\u52a8\u7248\u672c\u9009\u62e9</li> <li>\u5efa\u8bae\u5206\u6b65\u5b89\u88c5\u4ee5\u4fbf\u4e8e\u6392\u67e5\u53ef\u80fd\u7684\u95ee\u9898</li> <li>\u5b9a\u671f\u5907\u4efd\u73af\u5883\u914d\u7f6e\u6587\u4ef6</li> </ul>"},{"location":"DL_Engineering/Environment_Setup/#5","title":"5. \u5305\u8bf4\u660e","text":"<ul> <li>numpy, pandas: \u6570\u636e\u5904\u7406\u548c\u5206\u6790</li> <li>scipy: \u79d1\u5b66\u8ba1\u7b97</li> <li>matplotlib, seaborn: \u6570\u636e\u53ef\u89c6\u5316</li> <li>jupyter: \u4ea4\u4e92\u5f0f\u5f00\u53d1\u73af\u5883</li> <li>scikit-learn: \u673a\u5668\u5b66\u4e60\u5de5\u5177</li> <li>pillow, opencv: \u56fe\u50cf\u5904\u7406</li> <li>tqdm: \u8fdb\u5ea6\u6761\u663e\u793a</li> <li>ipywidgets: Jupyter \u4ea4\u4e92\u7ec4\u4ef6</li> </ul>"},{"location":"DL_Engineering/Environment_Setup/#6","title":"6. \u5e38\u89c1\u95ee\u9898\u6392\u67e5","text":"<ul> <li>\u5982\u679c\u5b89\u88c5\u5305\u65f6\u51fa\u73b0\u51b2\u7a81\uff0c\u5efa\u8bae\u5148\u521b\u5efa\u65b0\u73af\u5883</li> <li>\u786e\u4fdd\u5df2\u5b89\u88c5\u6700\u65b0\u7248\u672c\u7684conda</li> <li>\u68c0\u67e5\u73af\u5883\u53d8\u91cf\u662f\u5426\u6b63\u786e\u8bbe\u7f6e</li> <li>\u6ce8\u610f\u533a\u5206conda\u548cpip\u5b89\u88c5\u7684\u5305</li> </ul>"},{"location":"DL_Engineering/Pytorch_MLP/","title":"PyTorch MLP\u5b9e\u73b0\u8be6\u7ec6\u6307\u5357","text":"<p>\u6211\u4eec\u5c06\u8ba8\u8bba\u4ee5\u4e0b\u4e09\u90e8\u5206\uff1a</p> <ol> <li>\u795e\u7ecf\u7f51\u7edc\u5c42\u642d\u5efa\u65b9\u6cd5</li> <li>\u524d\u5411\u4f20\u64ad\u5b9a\u4e49\u65b9\u6cd5</li> <li>\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5</li> </ol> <p>\u6682\u65f6\u4e0d\u6d89\u53ca\u6570\u636e\u5904\u7406\u90e8\u5206\u3002\u6bcf\u4e2a\u90e8\u5206\u540e\u90fd\u4f1a\u6709\u76f8\u5e94\u7684**\u4e60\u9898**\uff0c\u5e2e\u52a9\u4f60\u901a\u8fc7\u7ec3\u4e60\u52a0\u6df1\u7406\u89e3\u3002</p>"},{"location":"DL_Engineering/Pytorch_MLP/#1","title":"1. \u795e\u7ecf\u7f51\u7edc\u5c42\u642d\u5efa\u65b9\u6cd5","text":"<p>\u5728 PyTorch \u4e2d\uff0c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u5c42\u4e3b\u8981\u901a\u8fc7\u7ee7\u627f <code>nn.Module</code> \u7c7b\uff0c\u5e76\u5728 <code>__init__</code> \u65b9\u6cd5\u4e2d\u5b9a\u4e49\u6240\u9700\u7684\u7f51\u7edc\u5c42\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u7528\u7684 PyTorch \u5355\u5143\u7ec4\u4ef6\u53ca\u5176\u5b9e\u73b0\u65b9\u5f0f\uff1a</p>"},{"location":"DL_Engineering/Pytorch_MLP/#11","title":"1.1 \u7ebf\u6027\u5c42\uff08\u5168\u8fde\u63a5\u5c42\uff09","text":"<p>\u7ec4\u4ef6\u8bf4\u660e\uff1a - <code>nn.Linear(in_features, out_features)</code>\uff1a\u5b9a\u4e49\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff0c\u8f93\u5165\u7279\u5f81\u6570\u4e3a <code>in_features</code>\uff0c\u8f93\u51fa\u7279\u5f81\u6570\u4e3a <code>out_features</code>\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>import torch.nn as nn\n\nclass BasicMLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(BasicMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)  # \u7b2c\u4e00\u5c42\u5168\u8fde\u63a5\n        self.fc2 = nn.Linear(hidden_size, output_size) # \u7b2c\u4e8c\u5c42\u5168\u8fde\u63a5\n\n    def forward(self, x):\n        # \u524d\u5411\u4f20\u64ad\u5b9a\u4e49\u5728\u4e0b\u4e00\u90e8\u5206\n        pass\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#12","title":"1.2 \u5377\u79ef\u5c42","text":"<p>\u867d\u7136\u6211\u4eec\u5f53\u524d\u4e13\u6ce8\u4e8e MLP\uff0c\u4f46\u4e86\u89e3\u5377\u79ef\u5c42\u6709\u52a9\u4e8e\u6269\u5c55\u7f51\u7edc\u7ed3\u6784\u3002</p> <p>\u7ec4\u4ef6\u8bf4\u660e\uff1a - <code>nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)</code>\uff1a\u4e8c\u7ef4\u5377\u79ef\u5c42\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>import torch.nn.functional as F\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # \u8f93\u5165\u901a\u90531\uff0c\u8f93\u51fa32\u901a\u9053\uff0c3x3\u5377\u79ef\u6838\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#13","title":"1.3 \u6fc0\u6d3b\u51fd\u6570","text":"<p>\u6fc0\u6d3b\u51fd\u6570\u5728\u7f51\u7edc\u5c42\u4e4b\u95f4\u5f15\u5165\u975e\u7ebf\u6027\u3002PyTorch \u63d0\u4f9b\u591a\u79cd\u6fc0\u6d3b\u51fd\u6570\uff0c\u901a\u8fc7 <code>torch.nn.functional</code> \u4f7f\u7528\u3002</p> <p>\u5e38\u7528\u6fc0\u6d3b\u51fd\u6570\uff1a - ReLU\uff1a<code>F.relu(x)</code> - Sigmoid\uff1a<code>F.sigmoid(x)</code> - Tanh\uff1a<code>F.tanh(x)</code></p> <p>\u793a\u4f8b\uff1a <pre><code>import torch.nn.functional as F\n\ndef forward(self, x):\n    x = F.relu(self.fc1(x))  # ReLU\u6fc0\u6d3b\n    x = self.fc2(x)\n    return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#14-dropout","title":"1.4 Dropout\u5c42","text":"<p>Dropout\u7528\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u901a\u8fc7\u968f\u673a\u5931\u6d3b\u90e8\u5206\u795e\u7ecf\u5143\u3002</p> <p>\u7ec4\u4ef6\u8bf4\u660e\uff1a - <code>nn.Dropout(p)</code>\uff1a\u4ee5\u6982\u7387 <code>p</code> \u968f\u673a\u5931\u6d3b\u795e\u7ecf\u5143\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>import torch.nn.functional as F\n\nclass AdvancedMLP(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(AdvancedMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, 512)\n        self.dropout = nn.Dropout(0.2)  # 20%\u7684dropout\u7387\n        self.fc2 = nn.Linear(512, output_size)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)  # \u5e94\u7528Dropout\n        x = self.fc2(x)\n        return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#15-batch-normalization","title":"1.5 \u6279\u5f52\u4e00\u5316\uff08Batch Normalization\uff09","text":"<p>\u6279\u5f52\u4e00\u5316\u5e2e\u52a9\u52a0\u901f\u8bad\u7ec3\u5e76\u7a33\u5b9a\u7f51\u7edc\u3002</p> <p>\u7ec4\u4ef6\u8bf4\u660e\uff1a - <code>nn.BatchNorm1d(num_features)</code>\uff1a\u4e00\u7ef4\u6279\u5f52\u4e00\u5316\uff0c\u5e38\u7528\u4e8e\u5168\u8fde\u63a5\u5c42\u3002 - <code>nn.BatchNorm2d(num_features)</code>\uff1a\u4e8c\u7ef4\u6279\u5f52\u4e00\u5316\uff0c\u5e38\u7528\u4e8e\u5377\u79ef\u5c42\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>import torch.nn.functional as F\n\nclass BNMLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(BNMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.bn1 = nn.BatchNorm1d(hidden_size)  # \u7b2c\u4e00\u5c42\u6279\u5f52\u4e00\u5316\n        self.fc2 = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.fc1(x)))  # \u5148\u7ebf\u6027\u53d8\u6362\uff0c\u518d\u6279\u5f52\u4e00\u5316\uff0c\u6700\u540e\u6fc0\u6d3b\n        x = self.fc2(x)\n        return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#1_1","title":"\u4e60\u9898 1\uff1a\u795e\u7ecf\u7f51\u7edc\u5c42\u642d\u5efa\u65b9\u6cd5","text":"<ol> <li> <p>\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u56db\u4e2a\u9690\u85cf\u5c42\u7684MLP\uff0c\u6bcf\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\u5206\u522b\u4e3a256\u3001128\u300164\u300132\u3002\u6bcf\u4e2a\u9690\u85cf\u5c42\u540e\u90fd\u6dfb\u52a0ReLU\u6fc0\u6d3b\u548cDropout\uff080.3\uff09\u7684\u64cd\u4f5c\uff0c\u6700\u540e\u8f93\u51fa\u5c42\u4e3a10\u4e2a\u8282\u70b9\u3002</p> <p>\u63d0\u793a\uff1a \u4f60\u9700\u8981\u5728 <code>__init__</code> \u4e2d\u5b9a\u4e49\u6240\u6709\u5c42\uff0c\u5e76\u5728 <code>forward</code> \u65b9\u6cd5\u4e2d\u6309\u987a\u5e8f\u8c03\u7528\u5b83\u4eec\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass FourLayerMLP(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(FourLayerMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, 256)\n        self.dropout1 = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(256, 128)\n        self.dropout2 = nn.Dropout(0.3)\n        self.fc3 = nn.Linear(128, 64)\n        self.dropout3 = nn.Dropout(0.3)\n        self.fc4 = nn.Linear(64, 32)\n        self.dropout4 = nn.Dropout(0.3)\n        self.output = nn.Linear(32, output_size)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = F.relu(self.fc3(x))\n        x = self.dropout3(x)\n        x = F.relu(self.fc4(x))\n        x = self.dropout4(x)\n        x = self.output(x)\n        return x\n</code></pre></p> <li> <p>\u5b9e\u73b0\u4e00\u4e2a\u5e26\u6709\u6279\u5f52\u4e00\u5316\u7684\u4e09\u5c42MLP\uff0c\u5176\u4e2d\u6bcf\u4e2a\u9690\u85cf\u5c42\u4f7f\u7528\u4e0d\u540c\u7684\u6fc0\u6d3b\u51fd\u6570\uff08\u5982ReLU\u3001Tanh\uff09\u3002</p> <p>\u63d0\u793a\uff1a \u4f7f\u7528 <code>nn.BatchNorm1d</code> \u4e3a\u5404\u5c42\u6dfb\u52a0\u6279\u5f52\u4e00\u5316\uff0c\u9009\u62e9\u4e0d\u540c\u7684\u6fc0\u6d3b\u51fd\u6570\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass BNThreeLayerMLP(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(BNThreeLayerMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n        self.output = nn.Linear(hidden_sizes[2], output_size)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.fc1(x)))    # \u7b2c\u4e00\u9690\u85cf\u5c42\u4f7f\u7528ReLU\n        x = F.tanh(self.bn2(self.fc2(x)))    # \u7b2c\u4e8c\u9690\u85cf\u5c42\u4f7f\u7528Tanh\n        x = F.relu(self.bn3(self.fc3(x)))    # \u7b2c\u4e09\u9690\u85cf\u5c42\u4f7f\u7528ReLU\n        x = self.output(x)\n        return x\n</code></pre></p> <li> <p>\u6269\u5c55 <code>SimpleCNN</code> \u7c7b\uff0c\u6dfb\u52a0\u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\uff08\u8f93\u51fa64\u901a\u9053\uff0c3x3\u5377\u79ef\u6838\uff09\uff0c\u5e76\u5728\u6bcf\u4e2a\u5377\u79ef\u5c42\u540e\u6dfb\u52a0ReLU\u6fc0\u6d3b\u548c\u6700\u5927\u6c60\u5316\u5c42\u3002</p> <p>\u63d0\u793a\uff1a \u5728 <code>__init__</code> \u4e2d\u589e\u52a0\u65b0\u7684\u5377\u79ef\u5c42\u548c\u6c60\u5316\u5c42\uff0c\u5728 <code>forward</code> \u65b9\u6cd5\u4e2d\u6309\u987a\u5e8f\u8c03\u7528\u5b83\u4eec\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass ExtendedCNN(nn.Module):\n    def __init__(self):\n        super(ExtendedCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # \u7b2c\u4e00\u5c42\u5377\u79ef\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1) # \u7b2c\u4e8c\u5c42\u5377\u79ef\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#2","title":"2. \u524d\u5411\u4f20\u64ad\u5b9a\u4e49\u65b9\u6cd5","text":"<p>\u524d\u5411\u4f20\u64ad\u662f\u6570\u636e\u901a\u8fc7\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b\u7684\u8fc7\u7a0b\u3002\u5728 <code>nn.Module</code> \u7684\u5b50\u7c7b\u4e2d\uff0c\u4f60\u9700\u8981\u5b9a\u4e49 <code>forward</code> \u65b9\u6cd5\uff0c\u63cf\u8ff0\u6570\u636e\u5728\u5404\u5c42\u4e4b\u95f4\u7684\u4f20\u9012\u65b9\u5f0f\u3002</p>"},{"location":"DL_Engineering/Pytorch_MLP/#21","title":"2.1 \u57fa\u672c\u524d\u5411\u4f20\u64ad","text":"<p>\u793a\u4f8b\uff1a <pre><code>def forward(self, x):\n    x = F.relu(self.fc1(x))  # \u7b2c\u4e00\u5c42\u7ebf\u6027\u53d8\u6362 + ReLU\u6fc0\u6d3b\n    x = self.fc2(x)          # \u7b2c\u4e8c\u5c42\u7ebf\u6027\u53d8\u6362\n    return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#22-dropout","title":"2.2 \u5305\u542bDropout\u7684\u524d\u5411\u4f20\u64ad","text":"<p>\u793a\u4f8b\uff1a <pre><code>def forward(self, x):\n    x = F.relu(self.fc1(x))\n    x = self.dropout(x)  # \u5e94\u7528Dropout\n    x = self.fc2(x)\n    return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#23","title":"2.3 \u4f7f\u7528\u6279\u5f52\u4e00\u5316\u7684\u524d\u5411\u4f20\u64ad","text":"<p>\u793a\u4f8b\uff1a <pre><code>def forward(self, x):\n    x = F.relu(self.bn1(self.fc1(x)))  # \u7ebf\u6027\u53d8\u6362 -&gt; \u6279\u5f52\u4e00\u5316 -&gt; ReLU\u6fc0\u6d3b\n    x = self.fc2(x)\n    return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#24","title":"2.4 \u591a\u5c42\u524d\u5411\u4f20\u64ad","text":"<p>\u793a\u4f8b\uff1a <pre><code>def forward(self, x):\n    x = F.relu(self.fc1(x))\n    x = self.dropout(x)\n    x = F.relu(self.fc2(x))\n    x = self.dropout(x)\n    x = self.fc3(x)\n    return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#2mlp","title":"\u4e60\u9898 2\uff1aMLP\u5b9e\u73b0\u65b9\u6cd5","text":"<ol> <li> <p>\u4e3a\u4e00\u4e2a\u56db\u5c42MLP\uff08\u5305\u542b\u4e09\u4e2a\u9690\u85cf\u5c42\uff09\u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u65b9\u6cd5\uff0c\u5176\u4e2d\u6bcf\u4e2a\u9690\u85cf\u5c42\u540e\u90fd\u6dfb\u52a0\u4e86ReLU\u6fc0\u6d3b\u548cDropout\u3002</p> <p>\u63d0\u793a\uff1a \u6309\u7167\u5b9a\u4e49\u7684\u5c42\u6570\u4f9d\u6b21\u8c03\u7528\uff0c\u5e76\u5728\u6bcf\u5c42\u540e\u6dfb\u52a0\u6fc0\u6d3b\u548cDropout\u64cd\u4f5c\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass FourLayerMLPWithDropout(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size, dropout_p=0.3):\n        super(FourLayerMLPWithDropout, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n        self.dropout1 = nn.Dropout(dropout_p)\n        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n        self.dropout2 = nn.Dropout(dropout_p)\n        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n        self.dropout3 = nn.Dropout(dropout_p)\n        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = F.relu(self.fc3(x))\n        x = self.dropout3(x)\n        x = self.fc4(x)\n        return x\n</code></pre></p> <li> <p>\u5b9e\u73b0\u4e00\u4e2a\u524d\u5411\u4f20\u64ad\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6bcf\u4e24\u4e2a\u7ebf\u6027\u5c42\u4e4b\u95f4\u6dfb\u52a0\u4e86\u4e00\u4e2a\u6b8b\u5dee\u8fde\u63a5\uff08Residual Connection\uff09\u3002</p> <p>\u63d0\u793a\uff1a \u5728\u524d\u5411\u4f20\u64ad\u4e2d\uff0c\u5c06\u8f93\u5165\u76f4\u63a5\u52a0\u5230\u7ecf\u8fc7\u4e24\u5c42\u53d8\u6362\u540e\u7684\u8f93\u51fa\u4e0a\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResidualMLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(ResidualMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, hidden_size)\n        self.fc3 = nn.Linear(hidden_size, output_size)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        identity = x  # \u4fdd\u5b58\u8f93\u5165\u4ee5\u4fbf\u6dfb\u52a0\u6b8b\u5dee\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        out += identity  # \u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5\n        out = self.relu(out)\n        out = self.fc3(out)\n        return out\n</code></pre></p> <li> <p>\u4e3a\u5305\u542b\u6279\u5f52\u4e00\u5316\u548c\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u7684MLP\u5b9a\u4e49\u524d\u5411\u4f20\u64ad\u65b9\u6cd5\u3002</p> <p>\u63d0\u793a\uff1a \u4f7f\u7528\u76f8\u5e94\u7684\u6fc0\u6d3b\u51fd\u6570\u548c\u6279\u5f52\u4e00\u5316\u5c42\uff0c\u786e\u4fdd\u987a\u5e8f\u6b63\u786e\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass AdvancedBNMLP(nn.Module):\n    def __init__(self, input_size, hidden_sizes, output_size):\n        super(AdvancedBNMLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n        self.bn1 = nn.BatchNorm1d(hidden_sizes[0])\n        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n        self.bn2 = nn.BatchNorm1d(hidden_sizes[1])\n        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n        self.bn3 = nn.BatchNorm1d(hidden_sizes[2])\n        self.output = nn.Linear(hidden_sizes[2], output_size)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.bn1(x)\n        x = F.relu(x)  # \u7b2c\u4e00\u9690\u85cf\u5c42\u4f7f\u7528ReLU\n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = F.tanh(x)  # \u7b2c\u4e8c\u9690\u85cf\u5c42\u4f7f\u7528Tanh\n        x = self.fc3(x)\n        x = self.bn3(x)\n        x = F.relu(x)  # \u7b2c\u4e09\u9690\u85cf\u5c42\u4f7f\u7528ReLU\n        x = self.output(x)\n        return x\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#3","title":"3. \u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5","text":"<p>\u6a21\u578b\u8bad\u7ec3\u6d89\u53ca\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u3001\u4f18\u5316\u5668\uff0c\u5e76\u8fdb\u884c\u8fed\u4ee3\u8bad\u7ec3\u4ee5\u6700\u5c0f\u5316\u635f\u5931\u3002\u4ee5\u4e0b\u662f PyTorch \u4e2d\u5e38\u89c1\u7684\u8bad\u7ec3\u65b9\u6cd5\u53ca\u7ec4\u4ef6\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002</p>"},{"location":"DL_Engineering/Pytorch_MLP/#31","title":"3.1 \u8bbe\u5907\u914d\u7f6e","text":"<p>\u786e\u4fdd\u6a21\u578b\u548c\u6570\u636e\u5728\u540c\u4e00\u8bbe\u5907\u4e0a\uff08CPU\u6216GPU\uff09\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = AdvancedMLP(input_size=784, output_size=10).to(device)\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#32","title":"3.2 \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668","text":"<p>\u635f\u5931\u51fd\u6570\uff1a - \u5206\u7c7b\u95ee\u9898\u5e38\u7528 <code>nn.CrossEntropyLoss</code> - \u56de\u5f52\u95ee\u9898\u5e38\u7528 <code>nn.MSELoss</code></p> <p>\u4f18\u5316\u5668\uff1a - \u5e38\u7528\u4f18\u5316\u5668\u6709 <code>torch.optim.SGD</code>\u3001<code>torch.optim.Adam</code> \u7b49\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n# \u6216\u4f7f\u7528Adam\u4f18\u5316\u5668\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#33","title":"3.3 \u8bad\u7ec3\u5faa\u73af","text":"<p>\u8bad\u7ec3\u8fc7\u7a0b\u5305\u62ec\u591a\u4e2a Epoch\uff0c\u6bcf\u4e2a Epoch \u5305\u542b\u82e5\u5e72 Batch\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>def train(model, train_loader, optimizer, criterion, epochs):\n    model.train()  # \u8bbe\u7f6e\u6a21\u578b\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n    for epoch in range(epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)  # \u6570\u636e\u642c\u79fb\u5230\u8bbe\u5907\n            optimizer.zero_grad()      # \u6e05\u96f6\u68af\u5ea6\n            output = model(data)       # \u524d\u5411\u4f20\u64ad\n            loss = criterion(output, target)  # \u8ba1\u7b97\u635f\u5931\n            loss.backward()            # \u53cd\u5411\u4f20\u64ad\n            optimizer.step()           # \u66f4\u65b0\u53c2\u6570\n\n            if batch_idx % 100 == 0:\n                print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]  Loss: {loss.item():.6f}')\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#34","title":"3.4 \u8bc4\u4f30\u51fd\u6570","text":"<p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6216\u4e4b\u540e\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002</p> <p>\u793a\u4f8b\uff1a <pre><code>def test(model, test_loader, criterion):\n    model.eval()  # \u8bbe\u7f6e\u6a21\u578b\u4e3a\u8bc4\u4f30\u6a21\u5f0f\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():  # \u5173\u95ed\u68af\u5ea6\u8ba1\u7b97\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += criterion(output, target).item()  # \u7d2f\u79ef\u635f\u5931\n            pred = output.argmax(dim=1, keepdim=True)      # \u83b7\u53d6\u9884\u6d4b\u7ed3\u679c\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader)\n    accuracy = 100. * correct / len(test_loader.dataset)\n    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\\n')\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#35","title":"3.5 \u5b8c\u6574\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u6d41\u7a0b","text":"<p>\u793a\u4f8b\uff1a <pre><code>if __name__ == '__main__':\n    train(epochs=5)\n    test()\n</code></pre></p>"},{"location":"DL_Engineering/Pytorch_MLP/#3_1","title":"\u4e60\u9898 3\uff1a\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5","text":"<ol> <li> <p>\u5728\u8bad\u7ec3\u5faa\u73af\u4e2d\u6dfb\u52a0\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u4f7f\u5b66\u4e60\u7387\u6bcf\u4e2aEpoch\u4e0b\u964d\u4e3a\u539f\u6765\u76840.7\u500d\u3002</p> <p>\u63d0\u793a\uff1a \u4f7f\u7528 <code>torch.optim.lr_scheduler.StepLR</code> \u5e76\u5728\u8bad\u7ec3\u5faa\u73af\u4e2d\u8c03\u7528 <code>scheduler.step()</code>\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\ndef train_with_scheduler(model, train_loader, optimizer, criterion, scheduler, epochs):\n    model.train()\n    for epoch in range(epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n            if batch_idx % 100 == 0:\n                print(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]  Loss: {loss.item():.6f}')\n        scheduler.step()  # \u66f4\u65b0\u5b66\u4e60\u7387\n        print(f'Learning rate after epoch {epoch}: {scheduler.get_last_lr()}')\n\n# \u4f7f\u7528\u793a\u4f8b\noptimizer = optim.Adam(model.parameters(), lr=0.01)\nscheduler = StepLR(optimizer, step_size=1, gamma=0.7)  # \u6bcf\u4e2aEpoch\u5b66\u4e60\u7387\u4e58\u4ee50.7\ntrain_with_scheduler(model, train_loader, optimizer, criterion, scheduler, epochs=10)\n</code></pre></p> <li> <p>\u5b9e\u73b0\u65e9\u505c\uff08Early Stopping\uff09\u673a\u5236\uff0c\u5f53\u9a8c\u8bc1\u96c6\u635f\u5931\u5728\u8fde\u7eed3\u4e2aEpoch\u4e2d\u6ca1\u6709\u4e0b\u964d\u65f6\uff0c\u63d0\u524d\u7ec8\u6b62\u8bad\u7ec3\u3002</p> <p>\u63d0\u793a\uff1a \u521b\u5efa\u4e00\u4e2a <code>EarlyStopping</code> \u7c7b\uff0c\u5e76\u5728\u6bcf\u4e2aEpoch\u7ed3\u675f\u540e\u68c0\u67e5\u9a8c\u8bc1\u635f\u5931\u662f\u5426\u6709\u4e0b\u964d\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch\nimport numpy as np\n\nclass EarlyStopping:\n    def __init__(self, patience=3, verbose=False, delta=0):\n        \"\"\"\n        Args:\n            patience (int): \u5728\u591a\u5c11\u4e2aEpoch\u5185\u9a8c\u8bc1\u635f\u5931\u6ca1\u6709\u4e0b\u964d\u65f6\u505c\u6b62\u8bad\u7ec3\n            verbose (bool): \u662f\u5426\u6253\u5370\u63d0\u793a\u4fe1\u606f\n            delta (float): \u9a8c\u8bc1\u635f\u5931\u4e0b\u964d\u7684\u6700\u5c0f\u53d8\u5316\u91cf\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.delta = delta\n        self.counter = 0\n        self.best_loss = np.Inf\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if val_loss &lt; self.best_loss - self.delta:\n            self.best_loss = val_loss\n            self.counter = 0\n            if self.verbose:\n                print(f'\u9a8c\u8bc1\u635f\u5931\u6539\u5584\uff0c\u8ba1\u6570\u5668\u91cd\u7f6e\u4e3a0')\n        else:\n            self.counter += 1\n            if self.verbose:\n                print(f'\u9a8c\u8bc1\u635f\u5931\u6ca1\u6709\u6539\u5584\uff0c\u8ba1\u6570\u5668\u589e\u52a0\u5230{self.counter}')\n            if self.counter &gt;= self.patience:\n                self.early_stop = True\n                if self.verbose:\n                    print('\u65e9\u505c\u89e6\u53d1\uff0c\u505c\u6b62\u8bad\u7ec3')\n\ndef train_with_early_stopping(model, train_loader, val_loader, optimizer, criterion, epochs, patience=3):\n    early_stopping = EarlyStopping(patience=patience, verbose=True)\n    for epoch in range(epochs):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n        # \u8bc4\u4f30\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u8868\u73b0\n        val_loss = 0\n        model.eval()\n        with torch.no_grad():\n            for data, target in val_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = criterion(output, target)\n                val_loss += loss.item()\n        val_loss /= len(val_loader)\n        print(f'Epoch: {epoch}  Validation Loss: {val_loss:.6f}')\n\n        early_stopping(val_loss)\n        if early_stopping.early_stop:\n            print(\"\u63d0\u524d\u505c\u6b62\u8bad\u7ec3\")\n            break\n\n# \u4f7f\u7528\u793a\u4f8b\ntrain_with_early_stopping(model, train_loader, val_loader, optimizer, criterion, epochs=50, patience=3)\n</code></pre></p> <li> <p>\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u6bcf\u4e2aEpoch\u540e\u6a21\u578b\u7684\u6743\u91cd\uff0c\u5e76\u5728\u8bad\u7ec3\u7ed3\u675f\u540e\u52a0\u8f7d\u6700\u4f73\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002</p> <p>\u63d0\u793a\uff1a \u4f7f\u7528 <code>torch.save</code> \u4fdd\u5b58\u6a21\u578b\u6743\u91cd\uff0c\u5e76\u5728\u9002\u5f53\u7684\u4f4d\u7f6e\u4f7f\u7528 <code>torch.load</code> \u52a0\u8f7d\u6743\u91cd\u3002</p> <p> \u67e5\u770b\u7b54\u6848 <p>\u53c2\u8003\u7b54\u6848\uff1a <pre><code>import torch\nimport os\n\ndef train_and_save_best_model(model, train_loader, val_loader, optimizer, criterion, epochs, save_path='best_model.pth'):\n    best_val_loss = np.Inf\n    for epoch in range(epochs):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n        # \u8bc4\u4f30\u5728\u9a8c\u8bc1\u96c6\u4e0a\u7684\u8868\u73b0\n        val_loss = 0\n        model.eval()\n        with torch.no_grad():\n            for data, target in val_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = criterion(output, target)\n                val_loss += loss.item()\n        val_loss /= len(val_loader)\n        print(f'Epoch: {epoch}  Validation Loss: {val_loss:.6f}')\n\n        # \u4fdd\u5b58\u6700\u597d\u7684\u6a21\u578b\n        if val_loss &lt; best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), save_path)\n            print(f'\u4fdd\u5b58\u6700\u4f73\u6a21\u578b\uff0c\u9a8c\u8bc1\u635f\u5931: {best_val_loss:.6f}')\n\n    print('\u8bad\u7ec3\u7ed3\u675f')\n\ndef load_best_model(model, load_path='best_model.pth'):\n    if os.path.exists(load_path):\n        model.load_state_dict(torch.load(load_path))\n        model.to(device)\n        print('\u52a0\u8f7d\u6700\u4f73\u6a21\u578b\u6743\u91cd\u6210\u529f')\n    else:\n        print('\u6700\u4f73\u6a21\u578b\u6743\u91cd\u6587\u4ef6\u4e0d\u5b58\u5728')\n\n# \u4f7f\u7528\u793a\u4f8b\ntrain_and_save_best_model(model, train_loader, val_loader, optimizer, criterion, epochs=20, save_path='best_model.pth')\nload_best_model(model, load_path='best_model.pth')\ntest(model, test_loader, criterion)\n</code></pre></p>"},{"location":"Dev_Agent/Python/Multi_Threads/","title":"1. \u591a\u7ebf\u7a0b\u7ba1\u7406\u7684\u7ec4\u4ef6\u7684\u4e00\u822c\u6a21\u677f\u662f\u4ec0\u4e48\u6837\u7684\uff1f","text":"<p><code>ThreadPoolExecutor</code> \u662f Python \u63d0\u4f9b\u7684\u4e00\u4e2a\u9ad8\u7ea7\u63a5\u53e3\uff0c\u7528\u4e8e\u7b80\u5316\u591a\u7ebf\u7a0b\u7ba1\u7406\u3002\u4ee5\u4e0b\u662f\u4e00\u4e2a\u5178\u578b\u7684\u4f7f\u7528 <code>ThreadPoolExecutor</code> \u7684\u6a21\u677f\uff1a</p> <pre><code>import concurrent.futures\n\ndef task_function(args):\n    # \u6267\u884c\u67d0\u4e2a\u4efb\u52a1\u7684\u903b\u8f91\n    return result\n\ndef main():\n    # \u5b9a\u4e49\u7ebf\u7a0b\u6c60\u7684\u6700\u5927\u5de5\u4f5c\u7ebf\u7a0b\u6570\n    max_workers = 5\n\n    # \u4f7f\u7528 ThreadPoolExecutor \u521b\u5efa\u4e00\u4e2a\u7ebf\u7a0b\u6c60\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # \u63d0\u4ea4\u591a\u4e2a\u4efb\u52a1\u5230\u7ebf\u7a0b\u6c60\n        futures = {executor.submit(task_function, arg): arg for arg in args_list}\n\n        # \u5904\u7406\u5b8c\u6210\u7684\u4efb\u52a1\n        for future in concurrent.futures.as_completed(futures):\n            arg = futures[future]\n            try:\n                result = future.result()\n                # \u5904\u7406\u7ed3\u679c\n            except Exception as e:\n                # \u5904\u7406\u5f02\u5e38\u60c5\u51b5\n                print(f\"\u4efb\u52a1 {arg} \u51fa\u9519: {e}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>\u5173\u952e\u7ec4\u6210\u90e8\u5206\u8bf4\u660e\uff1a</p> <ol> <li>\u521b\u5efa\u7ebf\u7a0b\u6c60\uff1a    <pre><code>with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n</code></pre></li> <li> <p><code>max_workers</code> \u51b3\u5b9a\u540c\u65f6\u8fd0\u884c\u7684\u7ebf\u7a0b\u6570\u3002\u9ed8\u8ba4\u503c\u901a\u5e38\u662f <code>min(32, os.cpu_count() + 4)</code>\u3002</p> </li> <li> <p>\u63d0\u4ea4\u4efb\u52a1\uff1a    <pre><code>futures = {executor.submit(task_function, arg): arg for arg in args_list}\n</code></pre></p> </li> <li> <p><code>executor.submit</code> \u7528\u4e8e\u63d0\u4ea4\u72ec\u7acb\u7684\u4efb\u52a1\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a <code>Future</code> \u5bf9\u8c61\u3002</p> </li> <li> <p>\u5904\u7406\u4efb\u52a1\u7ed3\u679c\uff1a    <pre><code>for future in concurrent.futures.as_completed(futures):\n    try:\n        result = future.result()\n        # \u5904\u7406\u7ed3\u679c\n    except Exception as e:\n        # \u5904\u7406\u5f02\u5e38\n</code></pre></p> </li> <li><code>as_completed</code> \u6309\u7167\u4efb\u52a1\u5b8c\u6210\u7684\u987a\u5e8f\u8fed\u4ee3 <code>Future</code> \u5bf9\u8c61\u3002</li> <li>\u4f7f\u7528 <code>future.result()</code> \u83b7\u53d6\u4efb\u52a1\u7684\u8fd4\u56de\u503c\uff0c\u5982\u679c\u4efb\u52a1\u629b\u51fa\u5f02\u5e38\uff0c\u5219\u4f1a\u5728\u8fd9\u91cc\u6355\u83b7\u3002</li> </ol>"},{"location":"Docker/docker_commands/","title":"Docker commands","text":"<p>\u5982\u4f55\u5c06\u6587\u4ef6\u4ece\u5bb9\u5668\u5185\u79fb\u52a8\u5230\u5bbf\u4e3b\u673a\u4e0a <pre><code>docker cp &lt;\u5bb9\u5668ID&gt;:&lt;\u5bb9\u5668\u5185\u6587\u4ef6\u8def\u5f84&gt; &lt;\u5bbf\u4e3b\u673a\u76ee\u6807\u8def\u5f84&gt;\n</code></pre> <pre><code>docker cp &lt;\u5bb9\u5668\u540d\u79f0&gt;:&lt;\u5bb9\u5668\u5185\u6587\u4ef6\u8def\u5f84&gt; &lt;\u5bbf\u4e3b\u673a\u76ee\u6807\u8def\u5f84&gt;\n</code></pre></p> <p>\u5982\u4f55\u4ece\u5bbf\u4e3b\u673a\u4e0a\u628a\u6587\u4ef6\u4f20\u8f93\u5230\u672c\u673a <pre><code>scp -p 1233 inuyasha@111.186.37.25:/home/inuyasha/data/bayuan_for_compile.json /Users/Inuyasha/Coding/Lean4Syntho/Semantic_Check/1101_Dataset_to_DPO\n</code></pre> \u6ce8\u610f\uff0cWindows\u8def\u5f84\u5e94\u8be5\u4f7f\u7528\u6b63\u659c\u6760\uff0c\u540c\u65f6\u4e0d\u9700\u8981\u52a0\u7cfb\u7edf\u76d8\u5f00\u5934</p>"},{"location":"Docker/docker_image_container/","title":"Docker\u955c\u50cf\u90e8\u7f72\u4e0e\u53d1\u5e03","text":"\u547d\u4ee4 \u7528\u9014 <code>docker build -t &lt;image_name&gt;:&lt;tag&gt; .</code> \u6784\u5efaDocker\u955c\u50cf <code>docker run -it --rm &lt;image_name&gt;:&lt;tag&gt;</code> \u8fd0\u884cDocker\u5bb9\u5668 <code>docker tag &lt;image_name&gt;:&lt;tag&gt; &lt;username&gt;/&lt;image_name&gt;:&lt;tag&gt;</code> \u4e3a\u955c\u50cf\u6dfb\u52a0\u65b0\u6807\u7b7e <code>docker push &lt;username&gt;/&lt;image_name&gt;:&lt;tag&gt;</code> \u63a8\u9001\u955c\u50cf\u5230\u4ed3\u5e93"},{"location":"Docker/docker_image_container/#1","title":"1. \u955c\u50cf\u6784\u5efa","text":"<pre><code>docker build -t lean4-mathlib:latest .\n</code></pre> <p>\u53c2\u6570\u89e3\u91ca\uff1a - <code>-t lean4-mathlib:latest</code>: \u4e3a\u6784\u5efa\u7684\u955c\u50cf\u6307\u5b9a\u540d\u79f0\u548c\u6807\u7b7e - <code>.</code>: \u6307\u5b9aDockerfile\u6240\u5728\u7684\u5f53\u524d\u76ee\u5f55\u4f5c\u4e3a\u6784\u5efa\u4e0a\u4e0b\u6587</p> <ul> <li>\u4f7f\u7528\u5f53\u524d\u76ee\u5f55\u7684Dockerfile\u6784\u5efa\u955c\u50cf</li> <li>\u6807\u8bb0\u955c\u50cf\u4e3a<code>lean4-mathlib:latest</code></li> </ul>"},{"location":"Docker/docker_image_container/#2","title":"2. \u672c\u5730\u6d4b\u8bd5","text":"<pre><code>docker run -it --rm lean4-mathlib:latest\n</code></pre> <p>\u53c2\u6570\u89e3\u91ca\uff1a - <code>-it</code>: \u4ee5\u4ea4\u4e92\u6a21\u5f0f\u8fd0\u884c\u5bb9\u5668\uff0c\u5e76\u5206\u914d\u4e00\u4e2a\u4f2a\u7ec8\u7aef - <code>--rm</code>: \u5bb9\u5668\u505c\u6b62\u8fd0\u884c\u540e\u81ea\u52a8\u5220\u9664 - <code>lean4-mathlib:latest</code>: \u6307\u5b9a\u8981\u8fd0\u884c\u7684\u955c\u50cf\u540d\u79f0\u548c\u6807\u7b7e</p> <ul> <li>\u4ea4\u4e92\u5f0f\u8fd0\u884c\u5bb9\u5668</li> <li><code>--rm</code>\u9009\u9879\u786e\u4fdd\u5bb9\u5668\u505c\u6b62\u540e\u81ea\u52a8\u5220\u9664</li> </ul>"},{"location":"Docker/docker_image_container/#3","title":"3. \u955c\u50cf\u63a8\u9001\uff08\u53ef\u9009\uff09","text":"<pre><code>docker tag lean4-mathlib:latest username/lean4-mathlib:latest\ndocker push username/lean4-mathlib:latest\n</code></pre> <p>\u53c2\u6570\u89e3\u91ca\uff1a - <code>docker tag</code>: \u4e3a\u955c\u50cf\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6807\u7b7e - <code>lean4-mathlib:latest</code>: \u6e90\u955c\u50cf\u540d\u79f0\u548c\u6807\u7b7e - <code>username/lean4-mathlib:latest</code>: \u76ee\u6807\u955c\u50cf\u540d\u79f0\u548c\u6807\u7b7e\uff0c\u901a\u5e38\u5305\u542bDocker Hub\u7528\u6237\u540d - <code>docker push</code>: \u5c06\u955c\u50cf\u63a8\u9001\u5230\u8fdc\u7a0b\u4ed3\u5e93</p> <ul> <li>\u91cd\u65b0\u6807\u8bb0\u955c\u50cf\u4ee5\u5339\u914dDocker Hub\u4ed3\u5e93\u540d</li> <li>\u63a8\u9001\u955c\u50cf\u5230Docker Hub</li> </ul>"},{"location":"Docker/dockerfile_construct/","title":"Lean4+Mathlib\u5f00\u53d1\u73af\u5883 Dockerfile \u6784\u5efa\u7ecf\u9a8c","text":""},{"location":"Docker/dockerfile_construct/#1-docker","title":"1. Docker \u547d\u4ee4\u6982\u89c8","text":"\u547d\u4ee4 \u63cf\u8ff0 \u793a\u4f8b FROM \u6307\u5b9a\u57fa\u7840\u955c\u50cf <code>FROM ubuntu:22.04</code> ENV \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf <code>ENV DEBIAN_FRONTEND=noninteractive</code> RUN \u6267\u884c shell \u547d\u4ee4 <code>RUN apt-get update &amp;&amp; apt-get install -y ...</code> USER \u5207\u6362\u5f53\u524d\u7528\u6237 <code>USER leanuser</code> WORKDIR \u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55 <code>WORKDIR /home/leanuser</code> CMD \u8bbe\u7f6e\u5bb9\u5668\u542f\u52a8\u65f6\u7684\u9ed8\u8ba4\u547d\u4ee4 <code>CMD [ \"bash\", \"-l\" ]</code>"},{"location":"Docker/dockerfile_construct/#2","title":"2. \u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u4f7f\u7528 <code>&amp;&amp;</code> \u8fde\u63a5\u591a\u4e2a\u547d\u4ee4\uff0c\u51cf\u5c11 RUN \u6307\u4ee4\u7684\u6570\u91cf\uff0c\u6709\u52a9\u4e8e\u51cf\u5c0f\u955c\u50cf\u5c42\u6570\u3002</li> <li>\u6e05\u7406\u4e0d\u5fc5\u8981\u7684\u6587\u4ef6\uff08\u5982 <code>apt-get clean</code>\uff09\uff0c\u51cf\u5c0f\u955c\u50cf\u5927\u5c0f\u3002</li> <li>\u4f7f\u7528\u975e root \u7528\u6237\u8fd0\u884c\u5e94\u7528\uff0c\u63d0\u9ad8\u5b89\u5168\u6027\u3002</li> <li>\u5c06\u9891\u7e41\u53d8\u52a8\u7684\u547d\u4ee4\u653e\u5728 Dockerfile \u7684\u540e\u9762\uff0c\u5229\u7528 Docker \u7684\u7f13\u5b58\u673a\u5236\u63d0\u9ad8\u6784\u5efa\u6548\u7387\u3002</li> </ol>"},{"location":"Docker/dockerfile_construct/#3","title":"3. \u8be6\u7ec6\u89e3\u6790","text":"<ol> <li>\u57fa\u7840\u955c\u50cf\u9009\u62e9 (FROM) <pre><code>FROM ubuntu:22.04\n</code></pre></li> <li> <p>\u6307\u5b9a\u57fa\u7840\u955c\u50cf\uff0c\u8fd9\u91cc\u4f7f\u7528 Ubuntu 22.04 LTS \u7248\u672c\u3002</p> </li> <li> <p>\u73af\u5883\u53d8\u91cf\u8bbe\u7f6e (ENV) <pre><code>ENV DEBIAN_FRONTEND=noninteractive\n</code></pre></p> </li> <li> <p>\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\uff0c\u7528\u4e8e\u914d\u7f6e\u5b89\u88c5\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u3002</p> </li> <li> <p>\u5305\u7ba1\u7406\u548c\u7cfb\u7edf\u4f9d\u8d56\u5b89\u88c5 (RUN) <pre><code>RUN apt-get update &amp;&amp; apt-get install -y ...\n</code></pre></p> </li> <li> <p>\u66f4\u65b0\u5305\u5217\u8868\u5e76\u5b89\u88c5\u5fc5\u8981\u7684\u7cfb\u7edf\u4f9d\u8d56\u3002</p> </li> <li> <p>\u7528\u6237\u521b\u5efa\u548c\u6743\u9650\u914d\u7f6e (RUN, USER) <pre><code>RUN useradd -m -s /bin/bash -G sudo leanuser\nUSER leanuser\n</code></pre></p> </li> <li>\u521b\u5efa\u975e root \u7528\u6237\u5e76\u914d\u7f6e sudo \u6743\u9650\u3002</li> <li> <p>\u5207\u6362\u5230\u65b0\u521b\u5efa\u7684\u7528\u6237\u3002</p> </li> <li> <p>\u5de5\u4f5c\u76ee\u5f55\u8bbe\u7f6e (WORKDIR) <pre><code>WORKDIR /home/leanuser\n</code></pre></p> </li> <li> <p>\u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\uff0c\u540e\u7eed\u547d\u4ee4\u5c06\u5728\u6b64\u76ee\u5f55\u4e0b\u6267\u884c\u3002</p> </li> <li> <p>Elan \u5b89\u88c5 (RUN) <pre><code>RUN curl -sSfL https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh | sh -s -- -y\n</code></pre></p> </li> <li> <p>\u4f7f\u7528\u5b98\u65b9\u811a\u672c\u5b89\u88c5 Elan\uff08Lean \u7248\u672c\u7ba1\u7406\u5668\uff09\u3002</p> </li> <li> <p>Lean \u5de5\u5177\u94fe\u5b89\u88c5 (RUN) <pre><code>RUN elan toolchain install $(cat lean-toolchain)\n</code></pre></p> </li> <li> <p>\u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684 Lean \u5de5\u5177\u94fe\u3002</p> </li> <li> <p>\u9879\u76ee\u521d\u59cb\u5316\u548c\u6784\u5efa (RUN) <pre><code>RUN lake update\nRUN lake build\n</code></pre></p> </li> <li> <p>\u4f7f\u7528 Lake \u66f4\u65b0\u9879\u76ee\u4f9d\u8d56\u5e76\u6784\u5efa\u9879\u76ee\u3002</p> </li> <li> <p>\u73af\u5883\u53d8\u91cf\u914d\u7f6e (RUN) <pre><code>RUN echo 'export LEAN_PATH=\"...\"' &gt;&gt; ~/.bashrc\n</code></pre></p> </li> <li> <p>\u914d\u7f6e Lean \u76f8\u5173\u7684\u73af\u5883\u53d8\u91cf\u3002</p> </li> <li> <p>\u9ed8\u8ba4\u542f\u52a8\u547d\u4ee4\u8bbe\u7f6e (CMD) <pre><code>CMD [ \"bash\", \"-l\" ]\n</code></pre></p> <ul> <li>\u8bbe\u7f6e\u5bb9\u5668\u542f\u52a8\u65f6\u7684\u9ed8\u8ba4\u547d\u4ee4\u3002</li> </ul> </li> </ol>"},{"location":"Docker/dockerfile_construct/#4-dockerfile","title":"4. \u9644\u5f55\uff1a\u539f\u59cbDockerfile","text":"<pre><code># \u4f7f\u7528\u5b98\u65b9\u7684 Ubuntu 22.04 LTS \u4f5c\u4e3a\u57fa\u7840\u955c\u50cf\nFROM ubuntu:22.04\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u4ee5\u907f\u514d\u5728\u5b89\u88c5\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u4ea4\u4e92\u63d0\u793a\nENV DEBIAN_FRONTEND=noninteractive\n\n# \u66f4\u65b0\u5305\u5217\u8868\u5e76\u5b89\u88c5\u5fc5\u8981\u7684\u7cfb\u7edf\u4f9d\u8d56\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    sudo \\\n    git \\\n    curl \\\n    bash-completion \\\n    python3 \\\n    python3-requests \\\n    build-essential \\\n    libffi-dev \\\n    libssl-dev \\\n    pkg-config \\\n    &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# \u521b\u5efa\u4e00\u4e2a\u975e root \u7528\u6237\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\nRUN useradd -m -s /bin/bash -G sudo leanuser \\\n    &amp;&amp; echo \"leanuser ALL=(ALL) NOPASSWD:ALL\" &gt;&gt; /etc/sudoers\n\n# \u5207\u6362\u5230\u975e root \u7528\u6237\nUSER leanuser\nWORKDIR /home/leanuser\n\n# \u5b89\u88c5 Elan\uff08Lean \u7248\u672c\u7ba1\u7406\u5668\uff09\nRUN curl -sSfL https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh | sh -s -- -y\n\n# \u5c06 Elan \u7684\u8def\u5f84\u6dfb\u52a0\u5230\u73af\u5883\u53d8\u91cf\u4e2d\nENV PATH=\"/home/leanuser/.elan/bin:${PATH}\"\n\n# \u5b89\u88c5 Lean \u5de5\u5177\u94fe\uff08\u6839\u636e mathlib \u7684 lean-toolchain \u6587\u4ef6\uff09\nRUN curl -s https://raw.githubusercontent.com/leanprover-community/mathlib4/master/lean-toolchain -o lean-toolchain \\\n    &amp;&amp; elan toolchain install $(cat lean-toolchain) \\\n    &amp;&amp; elan default $(cat lean-toolchain)\n\n# \u9a8c\u8bc1 Lake \u5b89\u88c5\nRUN lake --version\n\n# \u624b\u52a8\u521b\u5efa Lean \u9879\u76ee\u5e76\u6dfb\u52a0 Mathlib \u4f5c\u4e3a\u4f9d\u8d56\nRUN mkdir my_project &amp;&amp; \\\n    cd my_project &amp;&amp; \\\n    echo 'import Lake\\nopen Lake DSL\\n\\npackage \u00abmy_project\u00bb where\\n  -- add package configuration options here\\n\\nrequire mathlib from git\\n  \"https://github.com/leanprover-community/mathlib4.git\"\\n\\n@[default_target]\\nlean_lib \u00abMyProject\u00bb where\\n  -- add library configuration options here' &gt; lakefile.lean\n\n# \u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\u4e3a\u9879\u76ee\u76ee\u5f55\nWORKDIR /home/leanuser/my_project\n\n# \u521b\u5efa MyProject.lean \u6587\u4ef6\nRUN echo 'def hello := \"Hello from MyProject!\"' &gt; MyProject.lean\n\n# \u521d\u59cb\u5316\u9879\u76ee\u5e76\u66f4\u65b0\u4f9d\u8d56\nRUN lake update\n\n# \u6784\u5efa\u9879\u76ee\nRUN lake build\n\n# \u521b\u5efa\u6d4b\u8bd5\u6587\u4ef6\nRUN echo 'import Mathlib\\n\\ndef main : IO Unit :=\\n  IO.println s!\"Hello from Mathlib! {2 + 2}\"\\n\\n#eval main' &gt; test_mathlib.lean\n\n# \u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u4ee5\u5305\u542b\u6240\u6709\u5fc5\u8981\u7684\u5e93\u8def\u5f84\nRUN echo 'export LEAN_PATH=\"$LEAN_PATH:$(find .lake/packages -name lib -type d | tr \"\\n\" \":\" | sed \"s/:$//\")\"' &gt;&gt; ~/.bashrc\n\n# \u786e\u4fdd .bashrc \u5728\u6bcf\u6b21\u542f\u52a8\u65f6\u90fd\u88ab\u52a0\u8f7d\nRUN echo 'source ~/.bashrc' &gt;&gt; ~/.profile\n\n# \u8bbe\u7f6e\u9ed8\u8ba4\u7684\u542f\u52a8\u547d\u4ee4\nCMD [ \"bash\", \"-l\" ]\n</code></pre>"},{"location":"Docker/dockerfile_construct/#5-dockerfile","title":"5. \u539f\u59cbDockerfile\u8be6\u89e3","text":""},{"location":"Docker/dockerfile_construct/#_1","title":"\u57fa\u7840\u955c\u50cf\u9009\u62e9","text":"<pre><code>FROM ubuntu:22.04\n</code></pre> <ul> <li>\u9009\u62e9\u5b98\u65b9 Ubuntu 22.04 LTS \u4f5c\u4e3a\u57fa\u7840\u955c\u50cf\uff0c\u786e\u4fdd\u7a33\u5b9a\u6027\u548c\u957f\u671f\u652f\u6301\u3002</li> <li>\u8003\u8651\u4f7f\u7528\u66f4\u8f7b\u91cf\u7684\u57fa\u7840\u955c\u50cf\uff08\u5982 Alpine\uff09\u53ef\u80fd\u4f1a\u5e26\u6765\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u56e0\u6b64\u9009\u62e9 Ubuntu \u662f\u5b89\u5168\u7684\u9009\u62e9\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#_2","title":"\u7cfb\u7edf\u4f9d\u8d56\u5b89\u88c5","text":"<pre><code>ENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    sudo git curl bash-completion python3 python3-requests \\\n    build-essential libffi-dev libssl-dev pkg-config \\\n    &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre> <ul> <li>\u8bbe\u7f6e <code>DEBIAN_FRONTEND=noninteractive</code> \u907f\u514d\u5b89\u88c5\u8fc7\u7a0b\u4e2d\u7684\u4ea4\u4e92\u63d0\u793a\u3002</li> <li>\u5b89\u88c5\u5fc5\u8981\u7684\u7cfb\u7edf\u4f9d\u8d56\uff0c\u5305\u62ec\u7f16\u8bd1\u5de5\u5177\u548c Python \u73af\u5883\u3002</li> <li>\u4f7f\u7528 <code>apt-get clean</code> \u548c\u5220\u9664 <code>/var/lib/apt/lists/*</code> \u51cf\u5c0f\u955c\u50cf\u5927\u5c0f\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#_3","title":"\u7528\u6237\u5b89\u5168\u6027","text":"<pre><code>RUN useradd -m -s /bin/bash -G sudo leanuser \\\n    &amp;&amp; echo \"leanuser ALL=(ALL) NOPASSWD:ALL\" &gt;&gt; /etc/sudoers\n\nUSER leanuser\nWORKDIR /home/leanuser\n</code></pre> <ul> <li>\u521b\u5efa\u975e root \u7528\u6237 <code>leanuser</code> \u589e\u5f3a\u5b89\u5168\u6027\u3002</li> <li>\u5c06\u7528\u6237\u6dfb\u52a0\u5230 sudo \u7ec4\u5e76\u914d\u7f6e\u65e0\u5bc6\u7801 sudo \u6743\u9650\uff0c\u65b9\u4fbf\u540e\u7eed\u64cd\u4f5c\u3002</li> <li>\u5207\u6362\u5230\u975e root \u7528\u6237\uff0c\u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#elan","title":"Elan \u5b89\u88c5","text":"<pre><code>RUN curl -sSfL https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh | sh -s -- -y\n\nENV PATH=\"/home/leanuser/.elan/bin:${PATH}\"\n</code></pre> <ul> <li>\u4f7f\u7528\u5b98\u65b9\u811a\u672c\u5b89\u88c5 Elan\uff08Lean \u7248\u672c\u7ba1\u7406\u5668\uff09\u3002</li> <li>\u5c06 Elan \u7684\u8def\u5f84\u6dfb\u52a0\u5230\u73af\u5883\u53d8\u91cf\u4e2d\uff0c\u786e\u4fdd\u53ef\u4ee5\u5168\u5c40\u8bbf\u95ee\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#lean","title":"Lean \u5de5\u5177\u94fe\u5b89\u88c5","text":"<pre><code>RUN curl -s https://raw.githubusercontent.com/leanprover-community/mathlib4/master/lean-toolchain -o lean-toolchain \\\n    &amp;&amp; elan toolchain install $(cat lean-toolchain) \\\n    &amp;&amp; elan default $(cat lean-toolchain)\n</code></pre> <ul> <li>\u4ece mathlib \u4ed3\u5e93\u83b7\u53d6\u6700\u65b0\u7684 <code>lean-toolchain</code> \u6587\u4ef6\u3002</li> <li>\u5b89\u88c5\u6307\u5b9a\u7248\u672c\u7684 Lean \u5de5\u5177\u94fe\u5e76\u8bbe\u7f6e\u4e3a\u9ed8\u8ba4\u7248\u672c\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#_4","title":"\u9879\u76ee\u521d\u59cb\u5316","text":"<pre><code>RUN mkdir my_project &amp;&amp; cd my_project &amp;&amp; \\\n    echo 'import Lake\\nopen Lake DSL\\n\\npackage \u00abmy_project\u00bb where\\n  -- add package configuration options here\\n\\nrequire mathlib from git\\n  \"https://github.com/leanprover-community/mathlib4.git\"\\n\\n@[default_target]\\nlean_lib \u00abMyProject\u00bb where\\n  -- add library configuration options here' &gt; lakefile.lean\n\nWORKDIR /home/leanuser/my_project\n\nRUN echo 'def hello := \"Hello from MyProject!\"' &gt; MyProject.lean\n\nRUN lake update\nRUN lake build\n</code></pre> <ul> <li>\u624b\u52a8\u521b\u5efa Lean \u9879\u76ee\u7ed3\u6784\uff0c\u5305\u62ec <code>lakefile.lean</code> \u548c\u4e3b\u6587\u4ef6\u3002</li> <li>\u4f7f\u7528 <code>lake update</code> \u521d\u59cb\u5316\u9879\u76ee\u5e76\u66f4\u65b0\u4f9d\u8d56\u3002</li> <li>\u4f7f\u7528 <code>lake build</code> \u6784\u5efa\u9879\u76ee\uff0c\u786e\u4fdd\u73af\u5883\u6b63\u5e38\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#_5","title":"\u73af\u5883\u53d8\u91cf\u914d\u7f6e","text":"<pre><code>RUN echo 'export LEAN_PATH=\"$LEAN_PATH:$(find .lake/packages -name lib -type d | tr \"\\n\" \":\" | sed \"s/:$//\")\"' &gt;&gt; ~/.bashrc\nRUN echo 'source ~/.bashrc' &gt;&gt; ~/.profile\n</code></pre> <ul> <li>\u914d\u7f6e <code>LEAN_PATH</code> \u73af\u5883\u53d8\u91cf\uff0c\u5305\u542b\u6240\u6709\u5fc5\u8981\u7684\u5e93\u8def\u5f84\u3002</li> <li>\u786e\u4fdd\u6bcf\u6b21\u542f\u52a8\u5bb9\u5668\u65f6\u90fd\u52a0\u8f7d\u8fd9\u4e9b\u73af\u5883\u53d8\u91cf\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#_6","title":"\u542f\u52a8\u547d\u4ee4","text":"<pre><code>CMD [ \"bash\", \"-l\" ]\n</code></pre> <ul> <li>\u8bbe\u7f6e\u9ed8\u8ba4\u542f\u52a8\u547d\u4ee4\u4e3a\u767b\u5f55 shell\uff0c\u786e\u4fdd\u73af\u5883\u53d8\u91cf\u88ab\u6b63\u786e\u52a0\u8f7d\u3002</li> </ul>"},{"location":"Docker/dockerfile_construct/#6-lean4-dockerfile","title":"6. Lean4 Dockerfile \u6784\u5efa\u7ecf\u9a8c\u603b\u7ed3","text":"<ol> <li>\u7248\u672c\u63a7\u5236\uff1a\u4f7f\u7528 <code>lean-toolchain</code> \u6587\u4ef6\u786e\u4fdd Lean \u7248\u672c\u4e0e Mathlib \u517c\u5bb9\u3002</li> <li>\u4f9d\u8d56\u7ba1\u7406\uff1a\u901a\u8fc7 Elan \u548c Lake \u7ba1\u7406 Lean \u548c\u9879\u76ee\u4f9d\u8d56\uff0c\u7b80\u5316\u7248\u672c\u63a7\u5236\u3002</li> <li>\u5b89\u5168\u6027\uff1a\u4f7f\u7528\u975e root \u7528\u6237\u8fd0\u884c\u5e94\u7528\uff0c\u63d0\u9ad8\u5bb9\u5668\u5b89\u5168\u6027\u3002</li> <li>\u73af\u5883\u53d8\u91cf\uff1a\u6b63\u786e\u914d\u7f6e <code>LEAN_PATH</code> \u786e\u4fdd\u6240\u6709\u5e93\u8def\u5f84\u53ef\u8bbf\u95ee\u3002</li> <li>\u6784\u5efa\u9a8c\u8bc1\uff1a\u5728 Dockerfile \u4e2d\u8fdb\u884c\u9879\u76ee\u6784\u5efa\uff0c\u9a8c\u8bc1\u73af\u5883\u914d\u7f6e\u6b63\u786e\u3002</li> <li>\u955c\u50cf\u4f18\u5316\uff1a\u6e05\u7406\u4e0d\u5fc5\u8981\u7684\u6587\u4ef6\uff0c\u51cf\u5c0f\u6700\u7ec8\u955c\u50cf\u5927\u5c0f\u3002</li> </ol>"},{"location":"Lean4/Lean4_Python/","title":"Lean4 \u5217\u8868\u4e0e\u6570\u7ec4\u64cd\u4f5c\u6559\u7a0b","text":""},{"location":"Lean4/Lean4_Python/#_1","title":"\u5f15\u8a00","text":"<p>Lean4 \u662f\u4e00\u79cd\u5f3a\u5927\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff0c\u5728\u5904\u7406\u5217\u8868\u548c\u6570\u7ec4\u7b49\u6570\u636e\u7ed3\u6784\u65f6\u6709\u5176\u72ec\u7279\u7684\u65b9\u6cd5\u3002\u672c\u6559\u7a0b\u5c06\u8be6\u7ec6\u4ecb\u7ecd Lean4 \u4e2d\u7684\u5217\u8868\u548c\u6570\u7ec4\u64cd\u4f5c\uff0c\u5e76\u4e0e Python \u7684\u76f8\u5e94\u64cd\u4f5c\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e2e\u52a9\u60a8\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f7f\u7528 Lean4\u3002</p>"},{"location":"Lean4/Lean4_Python/#1","title":"1. \u57fa\u7840\u5de5\u5177","text":""},{"location":"Lean4/Lean4_Python/#11","title":"1.1 \u8303\u56f4\u521b\u5efa","text":"<p>Lean4 \u63d0\u4f9b\u4e86\u51e0\u79cd\u521b\u5efa\u8303\u56f4\u7684\u65b9\u6cd5\uff1a</p> <pre><code>-- \u521b\u5efa\u4ece 0 \u5230 9 \u7684\u8303\u56f4\n#eval List.range 10\n\n-- \u521b\u5efa\u4ece 5 \u5230 9 \u7684\u8303\u56f4\n#eval List.range 5 10\n</code></pre>"},{"location":"Lean4/Lean4_Python/#12","title":"1.2 \u81ea\u5b9a\u4e49\u6b65\u957f\u8303\u56f4\u51fd\u6570","text":"<p>\u5bf9\u4e8e\u9700\u8981\u81ea\u5b9a\u4e49\u6b65\u957f\u7684\u60c5\u51b5\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9e\u73b0\u4ee5\u4e0b\u51fd\u6570\uff1a</p> <pre><code>partial def rangeWithStep (start : Int) (end1 : Int) (step : Int) : List Int :=\n  if step == 0 then\n    []  -- \u6b65\u957f\u4e3a0\u65f6\u8fd4\u56de\u7a7a\u5217\u8868\n  else\n    let rec loop (current : Int) (acc : List Int) : List Int :=\n      if (step &gt; 0 &amp;&amp; current &gt;= end1) || (step &lt; 0 &amp;&amp; current &lt;= end1) then\n        acc\n      else\n        loop (current + step) (current :: acc)\n\n    if step &gt; 0 then\n      (loop start []).reverse  -- \u6b63\u5e8f\n    else\n      loop start []  -- \u5012\u5e8f\n\n-- \u6d4b\u8bd5\n#eval rangeWithStep 0 10 2    -- \u8f93\u51fa: [0, 2, 4, 6, 8]\n#eval rangeWithStep 10 0 (-2) -- \u8f93\u51fa: [10, 8, 6, 4, 2]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#13-let-def","title":"1.3 let \u548c def \u7684\u533a\u522b","text":"<ol> <li><code>let</code> \u58f0\u660e\uff1a\u7528\u4e8e\u521b\u5efa\u5c40\u90e8\u53d8\u91cf\u6216\u5c40\u90e8\u51fd\u6570\u3002</li> <li><code>def</code> \u58f0\u660e\uff1a\u7528\u4e8e\u5b9a\u4e49\u5168\u5c40\u51fd\u6570\u6216\u5e38\u91cf\u3002</li> </ol> <p>\u4f8b\u5b50\uff1a</p> <pre><code>def globalValue : Nat := 10  -- \u5168\u5c40\u5e38\u91cf\n\ndef exampleFunction : IO Unit := do\n  let localValue := 20  -- \u5c40\u90e8\u53d8\u91cf\n  IO.println s!\"Global value: {globalValue}\"\n  IO.println s!\"Local value: {localValue}\"\n\n#eval globalValue\n-- #eval localValue  -- \u8fd9\u4f1a\u62a5\u9519\n\n#eval let x := 5; x * 2\n</code></pre>"},{"location":"Lean4/Lean4_Python/#2","title":"2. \u5217\u8868\u64cd\u4f5c","text":""},{"location":"Lean4/Lean4_Python/#21","title":"2.1 \u521b\u5efa\u548c\u521d\u59cb\u5316","text":""},{"location":"Lean4/Lean4_Python/#python","title":"Python","text":"<pre><code>empty_list = []\nnon_empty_list = [1, 2, 3]\nlist_comprehension = [x for x in range(10)]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#lean4_1","title":"Lean4","text":"<pre><code>def emptyList : List Int := []\ndef nonEmptyList : List Int := [1, 2, 3]\ndef listFromRange : List Nat := List.range 10\n-- Lean4 \u4f7f\u7528 List.map \u5b9e\u73b0\u7c7b\u4f3c\u5217\u8868\u63a8\u5bfc\u5f0f\u7684\u529f\u80fd\ndef listComprehension : List Nat := (List.range 10).map (fun x =&gt; x * 2)\n</code></pre>"},{"location":"Lean4/Lean4_Python/#22","title":"2.2 \u8bbf\u95ee\u5143\u7d20","text":""},{"location":"Lean4/Lean4_Python/#python_1","title":"Python","text":"<pre><code>lst = [1, 2, 3, 4, 5]\nfirst = lst[0]\nlast = lst[-1]\nslice = lst[1:3]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#lean4_2","title":"Lean4","text":"<pre><code>def example_index_access : IO Unit := do\n  let lst : List Int := [1, 2, 3, 4, 5]\n\n  IO.println s!\"First element: {lst.get? 0}\"\n  IO.println s!\"Second element: {lst[1]!}\"  -- \u4f7f\u7528 ! \u64cd\u4f5c\u7b26\uff08\u4e0d\u5b89\u5168\uff09\n\n  -- \u83b7\u53d6\u6700\u540e\u4e00\u4e2a\u5143\u7d20\n  let last := lst.get? (lst.length - 1)\n  IO.println s!\"Last element: {last}\"\n\n  -- \u6a21\u62df\u5207\u7247\u64cd\u4f5c\n  let slice := (lst.drop 1).take 2\n  IO.println s!\"Slice: {slice}\"\n\n#eval example_index_access\n</code></pre>"},{"location":"Lean4/Lean4_Python/#23","title":"2.3 \u4fee\u6539\u5143\u7d20","text":"<p>Lean4 \u7684 List \u662f\u4e0d\u53ef\u53d8\u7684\uff0c\u9700\u8981\u521b\u5efa\u65b0\u5217\u8868\u6765\"\u4fee\u6539\"\u5143\u7d20\u3002</p> <pre><code>def modifyList (lst : List Int) : List Int :=\n  match lst with\n  | [] =&gt; []\n  | x :: xs =&gt; (x + 1) :: xs\n\n#eval modifyList [1, 2, 3]  -- \u8f93\u51fa: [2, 2, 3]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#24","title":"2.4 \u6dfb\u52a0\u5143\u7d20","text":""},{"location":"Lean4/Lean4_Python/#python_2","title":"Python","text":"<pre><code>lst = [1, 2, 3]\nlst.append(4)\nlst.insert(1, 5)\nlst.extend([6, 7])\n</code></pre>"},{"location":"Lean4/Lean4_Python/#lean4_3","title":"Lean4","text":"<pre><code>def exampleAddElements : IO Unit := do\n  let lst := [1, 2, 3]\n\n  let lstAppended := lst.append [4]\n  IO.println s!\"After append: {lstAppended}\"\n\n  let lstInserted := lst.insertAt 1 5\n  IO.println s!\"After insert: {lstInserted}\"\n\n  let lstExtended := lst ++ [6, 7]\n  IO.println s!\"After extend: {lstExtended}\"\n\n#eval exampleAddElements\n</code></pre>"},{"location":"Lean4/Lean4_Python/#25","title":"2.5 \u5220\u9664\u5143\u7d20","text":"<p>Lean4 \u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u521b\u5efa\u65b0\u5217\u8868\u6765\"\u5220\u9664\"\u5143\u7d20\uff1a</p> <pre><code>def removeElement (lst : List Int) (elem : Int) : List Int :=\n  lst.filter (\u00b7 \u2260 elem)\n\n#eval removeElement [1, 2, 3, 2, 4] 2  -- \u8f93\u51fa: [1, 3, 4]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#26","title":"2.6 \u6392\u5e8f","text":"<pre><code>def sortList (lst : List Int) : List Int :=\n  lst.qsort (\u00b7&lt;=\u00b7)\n\n#eval sortList [3, 1, 4, 1, 5, 9, 2, 6]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#3","title":"3. \u6570\u7ec4\u64cd\u4f5c","text":"<p>Lean4 \u4e2d\u7684\u6570\u7ec4\u662f\u53ef\u53d8\u7684\uff0c\u4f46\u64cd\u4f5c\u65b9\u5f0f\u4e0e\u5217\u8868\u6709\u6240\u4e0d\u540c\u3002</p>"},{"location":"Lean4/Lean4_Python/#31","title":"3.1 \u521b\u5efa\u548c\u521d\u59cb\u5316","text":"<pre><code>def emptyArray : Array Int := #[]\ndef nonEmptyArray : Array Int := #[1, 2, 3]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#32","title":"3.2 \u8bbf\u95ee\u548c\u4fee\u6539\u5143\u7d20","text":"<pre><code>def arrayOperations : IO Unit := do\n  let mut arr := #[1, 2, 3, 4, 5]\n\n  IO.println s!\"Original array: {arr}\"\n\n  -- \u8bbf\u95ee\u5143\u7d20\n  IO.println s!\"First element: {arr[0]!}\"\n\n  -- \u4fee\u6539\u5143\u7d20\n  arr := arr.set! 1 10\n  IO.println s!\"After modification: {arr}\"\n\n  -- \u6dfb\u52a0\u5143\u7d20\n  arr := arr.push 6\n  IO.println s!\"After adding element: {arr}\"\n\n  -- \u5220\u9664\u5143\u7d20\n  arr := arr.eraseIdx 2\n  IO.println s!\"After removing element: {arr}\"\n\n#eval arrayOperations\n</code></pre>"},{"location":"Lean4/Lean4_Python/#4","title":"4. \u9ad8\u7ea7\u64cd\u4f5c","text":""},{"location":"Lean4/Lean4_Python/#41-map","title":"4.1 \u6620\u5c04 (Map)","text":"<pre><code>def mapExample (lst : List Int) : List Int :=\n  lst.map (\u00b7 * 2)\n\n#eval mapExample [1, 2, 3, 4]  -- \u8f93\u51fa: [2, 4, 6, 8]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#42-filter","title":"4.2 \u8fc7\u6ee4 (Filter)","text":"<pre><code>def filterExample (lst : List Int) : List Int :=\n  lst.filter (\u00b7 % 2 == 0)\n\n#eval filterExample [1, 2, 3, 4, 5, 6]  -- \u8f93\u51fa: [2, 4, 6]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#43-fold","title":"4.3 \u6298\u53e0 (Fold)","text":"<pre><code>def sumList (lst : List Int) : Int :=\n  lst.foldl (\u00b7 + \u00b7) 0\n\n#eval sumList [1, 2, 3, 4, 5]  -- \u8f93\u51fa: 15\n</code></pre>"},{"location":"Lean4/Lean4_Python/#5","title":"5. \u6bd4\u8f83\u64cd\u4f5c","text":"<p>Lean4 \u4f7f\u7528 <code>Ord</code> \u7c7b\u578b\u7c7b\u8fdb\u884c\u6bd4\u8f83\u64cd\u4f5c\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u4f8b\u5b50\uff1a</p> <pre><code>#eval compare 5 10        -- \u7ed3\u679c: Ordering.lt\n#eval compare \"a\" \"b\"     -- \u7ed3\u679c: Ordering.lt\n#eval compare [1, 2] [1, 3] -- \u7ed3\u679c: Ordering.lt\n</code></pre>"},{"location":"Lean4/Lean4_Python/#6-ord","title":"6. \u6392\u5e8f\u548c Ord \u6bd4\u8f83","text":"<p>\u5728 Lean4 \u4e2d\uff0c\u6392\u5e8f\u548c\u6bd4\u8f83\u64cd\u4f5c\u901a\u5e38\u4f9d\u8d56\u4e8e <code>Ord</code> \u7c7b\u578b\u7c7b\u3002<code>Ord</code> \u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u5f0f\u6765\u6bd4\u8f83\u4e0d\u540c\u7c7b\u578b\u7684\u503c\u3002</p>"},{"location":"Lean4/Lean4_Python/#61-ord","title":"6.1 Ord \u7c7b\u578b\u7c7b","text":"<p><code>Ord</code> \u7c7b\u578b\u7c7b\u5b9a\u4e49\u4e86\u4ee5\u4e0b\u4e3b\u8981\u65b9\u6cd5\uff1a</p> <ul> <li><code>compare : \u03b1 \u2192 \u03b1 \u2192 Ordering</code>\uff1a\u6bd4\u8f83\u4e24\u4e2a\u503c\uff0c\u8fd4\u56de <code>Ordering.lt</code>\uff08\u5c0f\u4e8e\uff09\u3001<code>Ordering.eq</code>\uff08\u7b49\u4e8e\uff09\u6216 <code>Ordering.gt</code>\uff08\u5927\u4e8e\uff09\u3002</li> <li><code>(&lt;) : \u03b1 \u2192 \u03b1 \u2192 Bool</code>\uff1a\u5c0f\u4e8e\u6bd4\u8f83\u3002</li> <li><code>(\u2264) : \u03b1 \u2192 \u03b1 \u2192 Bool</code>\uff1a\u5c0f\u4e8e\u7b49\u4e8e\u6bd4\u8f83\u3002</li> <li><code>(&gt;) : \u03b1 \u2192 \u03b1 \u2192 Bool</code>\uff1a\u5927\u4e8e\u6bd4\u8f83\u3002</li> <li><code>(\u2265) : \u03b1 \u2192 \u03b1 \u2192 Bool</code>\uff1a\u5927\u4e8e\u7b49\u4e8e\u6bd4\u8f83\u3002</li> </ul>"},{"location":"Lean4/Lean4_Python/#62","title":"6.2 \u57fa\u672c\u7c7b\u578b\u7684\u6bd4\u8f83","text":"<pre><code>#eval compare 5 10        -- \u7ed3\u679c: Ordering.lt\n#eval compare 3.14 3.14   -- \u7ed3\u679c: Ordering.eq\n#eval compare 'a' 'b'     -- \u7ed3\u679c: Ordering.lt\n#eval compare \"hello\" \"world\"  -- \u7ed3\u679c: Ordering.lt\n#eval compare true false  -- \u7ed3\u679c: Ordering.gt\n</code></pre>"},{"location":"Lean4/Lean4_Python/#63","title":"6.3 \u590d\u5408\u7c7b\u578b\u7684\u6bd4\u8f83","text":"<p>\u5bf9\u4e8e\u5217\u8868\u3001\u6570\u7ec4\u7b49\u590d\u5408\u7c7b\u578b\uff0c\u6bd4\u8f83\u64cd\u4f5c\u901a\u5e38\u662f\u9010\u5143\u7d20\u8fdb\u884c\u7684\uff1a</p> <pre><code>#eval compare [1, 2, 3] [1, 2, 4]  -- \u7ed3\u679c: Ordering.lt\n#eval compare #[5, 6] #[5, 6, 7]   -- \u7ed3\u679c: Ordering.lt\n</code></pre>"},{"location":"Lean4/Lean4_Python/#64","title":"6.4 \u81ea\u5b9a\u4e49\u7c7b\u578b\u7684\u6bd4\u8f83","text":"<p>\u5bf9\u4e8e\u81ea\u5b9a\u4e49\u7c7b\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9e\u73b0 <code>Ord</code> \u5b9e\u4f8b\u6765\u5b9a\u4e49\u6bd4\u8f83\u884c\u4e3a\uff1a</p> <pre><code>structure Person where\n  name : String\n  age : Nat\nderiving Repr\n\ninstance : Ord Person where\n  compare p1 p2 :=\n    match compare p1.age p2.age with\n    | .eq =&gt; compare p1.name p2.name\n    | ord =&gt; ord\n\ndef alice : Person := { name := \"Alice\", age := 30 }\ndef bob : Person := { name := \"Bob\", age := 25 }\n\n#eval compare alice bob  -- \u7ed3\u679c: Ordering.gt\n</code></pre>"},{"location":"Lean4/Lean4_Python/#65","title":"6.5 \u6392\u5e8f\u64cd\u4f5c","text":"<p>Lean4 \u63d0\u4f9b\u4e86\u51e0\u79cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u5b83\u4eec\u90fd\u4f9d\u8d56\u4e8e <code>Ord</code> \u7c7b\u578b\u7c7b\uff1a</p>"},{"location":"Lean4/Lean4_Python/#651","title":"6.5.1 \u5217\u8868\u6392\u5e8f","text":"<pre><code>def sortList (lst : List Int) : List Int :=\n  lst.qsort (\u00b7&lt;=\u00b7)\n\n#eval sortList [3, 1, 4, 1, 5, 9, 2, 6]  -- \u8f93\u51fa: [1, 1, 2, 3, 4, 5, 6, 9]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#652","title":"6.5.2 \u6570\u7ec4\u6392\u5e8f","text":"<pre><code>def sortArray (arr : Array Int) : Array Int :=\n  arr.qsort (\u00b7&lt;=\u00b7)\n\n#eval sortArray #[3, 1, 4, 1, 5, 9, 2, 6]  -- \u8f93\u51fa: #[1, 1, 2, 3, 4, 5, 6, 9]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#653","title":"6.5.3 \u81ea\u5b9a\u4e49\u6bd4\u8f83\u51fd\u6570","text":"<p>\u6211\u4eec\u53ef\u4ee5\u63d0\u4f9b\u81ea\u5b9a\u4e49\u7684\u6bd4\u8f83\u51fd\u6570\u6765\u6539\u53d8\u6392\u5e8f\u884c\u4e3a\uff1a</p> <pre><code>def sortDescending (lst : List Int) : List Int :=\n  lst.qsort (\u00b7&gt;=\u00b7)\n\n#eval sortDescending [3, 1, 4, 1, 5, 9, 2, 6]  -- \u8f93\u51fa: [9, 6, 5, 4, 3, 2, 1, 1]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#66","title":"6.6 \u9ad8\u7ea7\u6392\u5e8f\u793a\u4f8b","text":""},{"location":"Lean4/Lean4_Python/#661","title":"6.6.1 \u6309\u591a\u4e2a\u6761\u4ef6\u6392\u5e8f","text":"<pre><code>def persons : List Person := [\n  { name := \"Alice\", age := 30 },\n  { name := \"Bob\", age := 25 },\n  { name := \"Charlie\", age := 30 }\n]\n\ndef sortPersons (ps : List Person) : List Person :=\n  ps.qsort (fun p1 p2 =&gt; \n    match compare p1.age p2.age with\n    | .eq =&gt; p1.name &lt;= p2.name\n    | .lt =&gt; true\n    | .gt =&gt; false\n  )\n\n#eval sortPersons persons\n-- \u8f93\u51fa: [{name := \"Bob\", age := 25}, {name := \"Alice\", age := 30}, {name := \"Charlie\", age := 30}]\n</code></pre>"},{"location":"Lean4/Lean4_Python/#662","title":"6.6.2 \u7a33\u5b9a\u6392\u5e8f","text":"<p>Lean4 \u7684 <code>qsort</code> \u4e0d\u4fdd\u8bc1\u7a33\u5b9a\u6027\u3002\u5982\u679c\u9700\u8981\u7a33\u5b9a\u6392\u5e8f\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>mergeSortBy</code>\uff1a</p> <pre><code>def stableSortPersons (ps : List Person) : List Person :=\n  ps.mergeSortBy (fun p1 p2 =&gt; p1.age &lt;= p2.age)\n\n#eval stableSortPersons persons\n</code></pre>"},{"location":"Lean4/Lean4_Python/#67","title":"6.7 \u6027\u80fd\u8003\u8651","text":"<ul> <li><code>qsort</code> \u901a\u5e38\u6bd4 <code>mergeSortBy</code> \u66f4\u5feb\uff0c\u4f46\u4e0d\u7a33\u5b9a\u3002</li> <li>\u5bf9\u4e8e\u5c0f\u5217\u8868\uff0c\u63d2\u5165\u6392\u5e8f\u53ef\u80fd\u66f4\u9ad8\u6548\u3002</li> <li>\u5bf9\u4e8e\u5927\u578b\u6570\u636e\u96c6\uff0c\u8003\u8651\u4f7f\u7528\u6570\u7ec4\u800c\u4e0d\u662f\u5217\u8868\uff0c\u56e0\u4e3a\u6570\u7ec4\u7684\u968f\u673a\u8bbf\u95ee\u66f4\u5feb\u3002</li> </ul>"},{"location":"Lean4/Lean4_Python/#_2","title":"\u603b\u7ed3","text":"<p>Lean4 \u4e2d\u7684\u6392\u5e8f\u548c\u6bd4\u8f83\u64cd\u4f5c\u4f9d\u8d56\u4e8e <code>Ord</code> \u7c7b\u578b\u7c7b\uff0c\u8fd9\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u548c\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u503c\u3002\u901a\u8fc7\u5b9e\u73b0 <code>Ord</code> \u5b9e\u4f8b\uff0c\u6211\u4eec\u53ef\u4ee5\u4e3a\u81ea\u5b9a\u4e49\u7c7b\u578b\u5b9a\u4e49\u6bd4\u8f83\u884c\u4e3a\uff0c\u4ece\u800c\u652f\u6301\u6392\u5e8f\u64cd\u4f5c\u3002Lean4 \u63d0\u4f9b\u4e86\u591a\u79cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u5982 <code>qsort</code> \u548c <code>mergeSortBy</code>\uff0c\u53ef\u4ee5\u6839\u636e\u9700\u8981\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u3002\u7406\u89e3\u8fd9\u4e9b\u6982\u5ff5\u5bf9\u4e8e\u9ad8\u6548\u5904\u7406\u548c\u7ec4\u7ec7\u6570\u636e\u7ed3\u6784\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u590d\u6742\u7684\u6570\u636e\u7c7b\u578b\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u3002</p>"},{"location":"Lean4/LeanFunction/","title":"Lean4 \u6570\u5b66\u6559\u7a0b\uff1a\u4ece\u7ebf\u6027\u65b9\u7a0b\u5230\u725b\u987f\u6cd5","text":""},{"location":"Lean4/LeanFunction/#_1","title":"\u5f15\u8a00","text":"<p>\u5728\u6570\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u4ea4\u53c9\u9886\u57df\uff0c\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u5b9a\u7406\u8bc1\u660e\u7cfb\u7edf\u6b63\u5728\u53d1\u6325\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u4f5c\u7528\u3002Lean4 \u4f5c\u4e3a\u4e00\u79cd\u5148\u8fdb\u7684\u5b9a\u7406\u8bc1\u660e\u52a9\u624b\u548c\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff0c\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\u6765\u63a2\u7d22\u6570\u5b66\u6982\u5ff5\u3001\u5b9e\u73b0\u7b97\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002</p> <p>\u672c\u6559\u7a0b\u7684\u76ee\u6807\u662f\u901a\u8fc7\u4e00\u7cfb\u5217\u6e10\u8fdb\u590d\u6742\u7684\u6570\u5b66\u95ee\u9898\uff0c\u5c55\u793a Lean4 \u5728\u6570\u5b66\u5efa\u6a21\u548c\u8ba1\u7b97\u65b9\u9762\u7684\u80fd\u529b\u3002\u6211\u4eec\u5c06\u4ece\u7b80\u5355\u7684\u7ebf\u6027\u65b9\u7a0b\u5f00\u59cb\uff0c\u9010\u6b65\u6df1\u5165\u5230\u4e8c\u6b21\u65b9\u7a0b\u7684\u6c42\u89e3\uff0c\u6700\u540e\u4ecb\u7ecd\u725b\u987f\u6cd5\u8fd9\u4e00\u5f3a\u5927\u7684\u6570\u503c\u65b9\u6cd5\u3002\u901a\u8fc7\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u6211\u4eec\u4e0d\u4ec5\u80fd\u5b66\u4e60\u5982\u4f55\u4f7f\u7528 Lean4 \u89e3\u51b3\u5b9e\u9645\u95ee\u9898\uff0c\u8fd8\u80fd\u6df1\u5165\u7406\u89e3\u6570\u5b66\u6982\u5ff5\u4e0e\u8ba1\u7b97\u673a\u5b9e\u73b0\u4e4b\u95f4\u7684\u8054\u7cfb\u3002</p>"},{"location":"Lean4/LeanFunction/#1","title":"1. \u7ebf\u6027\u65b9\u7a0b\uff1a\u7cbe\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u6743\u8861","text":"<p>\u6211\u4eec\u9996\u5148\u4ece\u6700\u57fa\u672c\u7684\u6570\u5b66\u6982\u5ff5\u4e4b\u4e00 \u2014\u2014 \u7ebf\u6027\u65b9\u7a0b\u5f00\u59cb\u3002\u7ebf\u6027\u65b9\u7a0b\u5f62\u5982 ax + b = 0\uff0c\u5176\u4e2d a \u548c b \u662f\u5e38\u6570\uff0cx \u662f\u672a\u77e5\u6570\u3002\u5728 Lean4 \u4e2d\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u591a\u79cd\u65b9\u5f0f\u8868\u793a\u548c\u6c42\u89e3\u8fd9\u7c7b\u65b9\u7a0b\uff0c\u6bcf\u79cd\u65b9\u5f0f\u90fd\u6709\u5176\u72ec\u7279\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002</p>"},{"location":"Lean4/LeanFunction/#11-q","title":"1.1 \u4f7f\u7528\u6709\u7406\u6570 (\u211a)","text":"<pre><code>import Mathlib.Data.Real.Basic\n\nstructure LinearEquation where\n  a : \u211a\n  b : \u211a\nderiving Repr\n\ndef solveLinearEquation (eq : LinearEquation) : Option \u211a :=\n  if eq.a = 0 then\n    if eq.b = 0 then some 0 else none\n  else\n    some (-eq.b / eq.a)\n\n-- \u793a\u4f8b\u4f7f\u7528\u4ee3\u7801\u7701\u7565...\n</code></pre> <p>\u4f7f\u7528\u6709\u7406\u6570\u7684\u4f18\u52bf\u5728\u4e8e\u5b83\u63d0\u4f9b\u4e86\u7cbe\u786e\u7684\u7ed3\u679c\uff0c\u907f\u514d\u4e86\u6d6e\u70b9\u6570\u8ba1\u7b97\u4e2d\u7684\u820d\u5165\u8bef\u5dee\u3002\u8fd9\u5bf9\u4e8e\u9700\u8981\u9ad8\u7cbe\u5ea6\u7684\u6570\u5b66\u8bc1\u660e\u6216\u91d1\u878d\u8ba1\u7b97\u7279\u522b\u6709\u7528\u3002\u7136\u800c\uff0c\u6709\u7406\u6570\u8fd0\u7b97\u53ef\u80fd\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6548\u7387\u8f83\u4f4e\uff0c\u7279\u522b\u662f\u5f53\u5206\u5b50\u6216\u5206\u6bcd\u53d8\u5f97\u975e\u5e38\u5927\u65f6\u3002</p>"},{"location":"Lean4/LeanFunction/#12-float","title":"1.2 \u4f7f\u7528\u6d6e\u70b9\u6570 (Float)","text":"<pre><code>import Mathlib\n\nstructure LinearEquation where\n  a : Float\n  b : Float\n\ndef solveLinearEquation (eq : LinearEquation) : Option Float :=\n  if eq.a == 0 then\n    if eq.b == 0 then some 0 else none\n  else\n    some (-eq.b / eq.a)\n\n-- \u793a\u4f8b\u4f7f\u7528\u4ee3\u7801\u7701\u7565...\n</code></pre> <p>\u6d6e\u70b9\u6570\u5b9e\u73b0\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002\u5b83\u5141\u8bb8\u5feb\u901f\u8ba1\u7b97\uff0c\u5e76\u4e14\u53ef\u4ee5\u5904\u7406\u975e\u5e38\u5927\u6216\u975e\u5e38\u5c0f\u7684\u6570\u503c\u3002\u7136\u800c\uff0c\u6d6e\u70b9\u6570\u8ba1\u7b97\u53ef\u80fd\u5bfc\u81f4\u7cbe\u5ea6\u635f\u5931\uff0c\u8fd9\u5728\u67d0\u4e9b\u79d1\u5b66\u8ba1\u7b97\u6216\u91d1\u878d\u5e94\u7528\u4e2d\u53ef\u80fd\u662f\u4e0d\u53ef\u63a5\u53d7\u7684\u3002</p>"},{"location":"Lean4/LeanFunction/#13-r","title":"1.3 \u4f7f\u7528\u5b9e\u6570 (\u211d)","text":"<pre><code>import Mathlib.Data.Real.Basic\n\nstructure LinearEquation where\n  a : \u211d\n  b : \u211d\n\nnoncomputable def solveLinearEquation (eq : LinearEquation) : Option \u211d :=\n  if eq.a = 0 then\n    if eq.b = 0 then some 0 else none\n  else\n    some (-eq.b / eq.a)\n</code></pre> <p>\u4f7f\u7528\u5b9e\u6570\u7c7b\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u7cbe\u786e\u6027\uff0c\u8fd9\u5728\u6570\u5b66\u8bc1\u660e\u4e2d\u975e\u5e38\u6709\u7528\u3002\u7136\u800c\uff0c\u5b9e\u6570\u5728 Lean4 \u4e2d\u88ab\u6807\u8bb0\u4e3a <code>noncomputable</code>\uff0c\u610f\u5473\u7740\u5b83\u4eec\u4e0d\u80fd\u7528\u4e8e\u5b9e\u9645\u7684\u8ba1\u7b97\u3002\u8fd9\u79cd\u5b9e\u73b0\u4e3b\u8981\u7528\u4e8e\u5f62\u5f0f\u5316\u6570\u5b66\u7406\u8bba\u548c\u5b9a\u7406\u8bc1\u660e\u3002</p> <p>\u901a\u8fc7\u6bd4\u8f83\u8fd9\u4e09\u79cd\u5b9e\u73b0\uff0c\u6211\u4eec\u53ef\u4ee5\u6df1\u5165\u7406\u89e3\u6570\u503c\u8868\u793a\u548c\u8ba1\u7b97\u7684\u4e0d\u540c\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u7cbe\u786e\u6027\u3001\u6548\u7387\u548c\u7406\u8bba\u57fa\u7840\u65b9\u9762\u7684\u6743\u8861\u3002\u8fd9\u79cd\u7406\u89e3\u5bf9\u4e8e\u9009\u62e9\u5408\u9002\u7684\u6570\u636e\u7c7b\u578b\u548c\u7b97\u6cd5\u6765\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002</p>"},{"location":"Lean4/LeanFunction/#2","title":"2. \u4e8c\u6b21\u65b9\u7a0b\uff1a\u5904\u7406\u590d\u6742\u6027\u548c\u7279\u6b8a\u60c5\u51b5","text":"<p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u63a2\u8ba8\u66f4\u590d\u6742\u7684\u4e8c\u6b21\u65b9\u7a0b\u6c42\u89e3\u3002\u4e8c\u6b21\u65b9\u7a0b\u4e0d\u4ec5\u5f15\u5165\u4e86\u66f4\u591a\u7684\u6570\u5b66\u590d\u6742\u6027\uff0c\u8fd8\u9700\u8981\u6211\u4eec\u8003\u8651\u591a\u79cd\u7279\u6b8a\u60c5\u51b5\uff0c\u5982\u65e0\u89e3\u3001\u5355\u89e3\u548c\u53cc\u89e3\u3002</p> <pre><code>import Mathlib\n\nstructure QuadraticEquation where\n  a : Float\n  b : Float\n  c : Float\nderiving Repr\n\ndef solveQuadraticEquation (eq : QuadraticEquation) : Option (Float \u00d7 Float) :=\n  if eq.a == 0 then\n    -- \u5904\u7406\u9000\u5316\u4e3a\u7ebf\u6027\u65b9\u7a0b\u7684\u60c5\u51b5\n    if eq.b != 0 then\n      let x := -eq.c / eq.b\n      some (x, x)\n    else\n      none\n  else\n    -- \u8ba1\u7b97\u5224\u522b\u5f0f\n    let discriminant := eq.b * eq.b - 4 * eq.a * eq.c\n    if discriminant &lt; 0 then\n      none  -- \u65e0\u5b9e\u6570\u89e3\n    else if discriminant == 0 then\n      -- \u552f\u4e00\u89e3\n      let x := -eq.b / (2 * eq.a)\n      some (x, x)\n    else\n      -- \u4e24\u4e2a\u4e0d\u540c\u7684\u89e3\n      let sqrtD := Float.sqrt discriminant\n      let x1 := (-eq.b + sqrtD) / (2 * eq.a)\n      let x2 := (-eq.b - sqrtD) / (2 * eq.a)\n      some (x1, x2)\n\n-- \u793a\u4f8b\u4f7f\u7528\u4ee3\u7801\u7701\u7565...\n</code></pre> <p>\u8fd9\u4e2a\u5b9e\u73b0\u5c55\u793a\u4e86\u5982\u4f55\u5904\u7406\u5404\u79cd\u8fb9\u754c\u60c5\u51b5\u548c\u7279\u6b8a\u60c5\u51b5\uff0c\u8fd9\u662f\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6280\u80fd\u3002\u6211\u4eec\u9700\u8981\u8003\u8651\uff1a 1. \u65b9\u7a0b\u9000\u5316\u4e3a\u7ebf\u6027\u65b9\u7a0b\u7684\u60c5\u51b5 (a = 0) 2. \u65e0\u89e3\u7684\u60c5\u51b5\uff08\u5224\u522b\u5f0f\u5c0f\u4e8e0\uff09 3. \u5355\u89e3\u7684\u60c5\u51b5\uff08\u5224\u522b\u5f0f\u7b49\u4e8e0\uff09 4. \u53cc\u89e3\u7684\u60c5\u51b5\uff08\u5224\u522b\u5f0f\u5927\u4e8e0\uff09</p> <p>\u901a\u8fc7\u8fd9\u4e2a\u4f8b\u5b50\uff0c\u6211\u4eec\u4e0d\u4ec5\u5b66\u4e60\u4e86\u5982\u4f55\u5728 Lean4 \u4e2d\u5b9e\u73b0\u590d\u6742\u7684\u6570\u5b66\u7b97\u6cd5\uff0c\u8fd8\u6df1\u5165\u7406\u89e3\u4e86\u6570\u5b66\u7406\u8bba\u4e0e\u5b9e\u9645\u7f16\u7a0b\u4e4b\u95f4\u7684\u8054\u7cfb\u3002</p>"},{"location":"Lean4/LeanFunction/#3","title":"3. \u725b\u987f\u6cd5\uff1a\u6570\u503c\u65b9\u6cd5\u4e0e\u8fed\u4ee3\u7b97\u6cd5","text":"<p>\u6700\u540e\uff0c\u6211\u4eec\u4ecb\u7ecd\u725b\u987f\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u6570\u503c\u65b9\u6cd5\uff0c\u7528\u4e8e\u5bfb\u627e\u51fd\u6570\u7684\u6839\u3002\u725b\u987f\u6cd5\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u5fae\u79ef\u5206\u6982\u5ff5\u8f6c\u5316\u4e3a\u8ba1\u7b97\u673a\u7b97\u6cd5\u3002</p> <pre><code>import Mathlib.Data.Real.Basic\nimport Mathlib.Analysis.SpecialFunctions.Sqrt\n\nstructure Function where\n  f : Float \u2192 Float\n  f' : Float \u2192 Float  -- \u5bfc\u6570\n\ndef newtonMethod (func : Function) (x0 : Float) (tolerance : Float) (maxIterations : Nat) : Float :=\n  let rec iterate (x : Float) (n : Nat) : Float :=\n    if n = 0 then x\n    else\n      let fx := func.f x\n      if fx.abs &lt; tolerance then x\n      else\n        let x' := x - fx / func.f' x\n        iterate x' (n - 1)\n  iterate x0 maxIterations\n\n-- \u793a\u4f8b\u4f7f\u7528\u4ee3\u7801\u7701\u7565...\n</code></pre> <p>\u725b\u987f\u6cd5\u7684\u5b9e\u73b0\u4f53\u73b0\u4e86\u51e0\u4e2a\u91cd\u8981\u7684\u7f16\u7a0b\u548c\u6570\u5b66\u6982\u5ff5\uff1a 1. \u9012\u5f52\u548c\u8fed\u4ee3\uff1a\u901a\u8fc7\u9012\u5f52\u51fd\u6570\u5b9e\u73b0\u8fed\u4ee3\u8fc7\u7a0b\u3002 2. \u6536\u655b\u6761\u4ef6\uff1a\u4f7f\u7528\u5bb9\u5dee\uff08tolerance\uff09\u6765\u5224\u65ad\u662f\u5426\u8fbe\u5230\u8db3\u591f\u7cbe\u786e\u7684\u89e3\u3002 3. \u51fd\u6570\u4f5c\u4e3a\u4e00\u7b49\u516c\u6c11(\u5373\u53ef\u4ee5\u8d4b\u503c\u3001\u53ef\u4ee5\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u3001\u53ef\u4ee5\u88ab\u8fd4\u56de)\uff1a\u5c06\u51fd\u6570\u53ca\u5176\u5bfc\u6570\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u3002</p> <pre><code>-- \u7ebf\u6027\u65b9\u7a0b\u793a\u4f8b\ndef example1 := LinearEquation.mk 2 (-4)\n#eval printSolution example1\n\n-- \u4e8c\u6b21\u65b9\u7a0b\u793a\u4f8b\ndef quadExample := QuadraticEquation.mk 1 (-5) 6\n#eval printSolution quadExample\n\n-- \u725b\u987f\u6cd5\u793a\u4f8b\ndef sqrt2Approximation : Float :=\n  newtonMethod squareRootFunction 1.5 0.0001 20\n#eval sqrt2Approximation\n</code></pre>"},{"location":"Lean4/LeetCode/","title":"\u4f7f\u7528lean4\u6c42\u89e3Leetcode","text":"<p>leetcode 9</p> <p><pre><code>def romanToInt (s : String) : Nat :=\n  let romanValues : Char \u2192 Nat\n    | 'I' =&gt; 1\n    | 'V' =&gt; 5\n    | 'X' =&gt; 10\n    | 'L' =&gt; 50\n    | 'C' =&gt; 100\n    | 'D' =&gt; 500\n    | 'M' =&gt; 1000\n    | _ =&gt; 0\n\n  let rec loop (chars : List Char) (total : Nat) (prevValue : Nat) : Nat :=\n    match chars with\n    | [] =&gt; total\n    | c::rest =&gt;\n      let currentValue := romanValues c\n      if currentValue &gt;= prevValue then\n        loop rest (total + currentValue) currentValue\n      else\n        loop rest (total - currentValue) currentValue\n\n  loop (s.toList.reverse) 0 0\n\n#eval romanToInt \"III\"       -- \u5e94\u8be5\u8fd4\u56de 3\n#eval romanToInt \"IV\"        -- \u5e94\u8be5\u8fd4\u56de 4\n#eval romanToInt \"IX\"        -- \u5e94\u8be5\u8fd4\u56de 9\n#eval romanToInt \"LVIII\"     -- \u5e94\u8be5\u8fd4\u56de 58\n#eval romanToInt \"MCMXCIV\"   -- \u5e94\u8be5\u8fd4\u56de 1994\n</code></pre> leetcode 14 <pre><code>partial def longestCommonPrefix (strs : List String) : String :=\n  match strs with\n  | [] =&gt; \"\"\n  | first :: rest =&gt;\n    let rec findPrefix (pre : String) (strings : List String) : String :=\n      match strings with\n      | [] =&gt; pre\n      | str :: rest' =&gt;\n        let newPre := pre.take (min pre.length str.length)\n        if str.startsWith newPre then\n          findPrefix newPre rest'\n        else if newPre.length &gt; 0 then\n          findPrefix (newPre.dropRight 1) strings\n        else\n          \"\"\n\n    findPrefix first rest\n\n#eval longestCommonPrefix [\"flower\", \"flow\", \"flight\"]  -- \u5e94\u8be5\u8fd4\u56de \"fl\"\n#eval longestCommonPrefix [\"dog\", \"racecar\", \"car\"]     -- \u5e94\u8be5\u8fd4\u56de \"\"\n#eval longestCommonPrefix []                            -- \u5e94\u8be5\u8fd4\u56de \"\"\n#eval longestCommonPrefix [\"a\"]                         -- \u5e94\u8be5\u8fd4\u56de \"a\"\n</code></pre> leetcode 20 <pre><code>def isValid (s : String) : Bool :=\n  let pair : Char \u2192 Option Char\n    | '(' =&gt; some ')'\n    | '[' =&gt; some ']'\n    | '{' =&gt; some '}'\n    | _ =&gt; none\n\n  let rec check (stack : List Char) (chars : List Char) : Bool :=\n    match chars with\n    | [] =&gt; stack.isEmpty\n    | c :: rest =&gt;\n      match pair c with\n      | some _ =&gt; check (c :: stack) rest\n      | none =&gt;\n        match stack with\n        | [] =&gt; false\n        | top :: stackRest =&gt;\n          if pair top == some c then\n            check stackRest rest\n          else\n            false\n\n  check [] s.toList\n\n#eval isValid \"()\"        -- \u5e94\u8be5\u8fd4\u56de true\n#eval isValid \"()[]{}\"    -- \u5e94\u8be5\u8fd4\u56de true\n#eval isValid \"(]\"        -- \u5e94\u8be5\u8fd4\u56de false\n#eval isValid \"([)]\"      -- \u5e94\u8be5\u8fd4\u56de false\n#eval isValid \"{[]}\"      -- \u5e94\u8be5\u8fd4\u56de true\n</code></pre> leetcode 26</p> <pre><code>partial def removeDuplicates (nums : Array Int) : Nat \u00d7 Array Int :=\n  if nums.isEmpty then\n    (0, #[])\n  else\n    let rec loop (i : Nat) (uniqueCount : Nat) (result : Array Int) :=\n      if i &gt;= nums.size then\n        (uniqueCount, result)\n      else if i = 0 || nums[i]! \u2260 nums[i-1]! then\n        loop (i+1) (uniqueCount+1) (result.push nums[i]!)\n      else\n        loop (i+1) uniqueCount result\n    loop 0 0 #[]\n\n#eval removeDuplicates #[1, 1, 2]\n#eval removeDuplicates #[0, 0, 1, 1, 1, 2, 2, 3, 3, 4]\n</code></pre>"},{"location":"Lean4/Algorithm/Data_Structure/Binary_Tree/","title":"Binary Tree","text":"<pre><code>import Std\n-- \u8fd9\u5c31\u662f\u8bf4\u53f6\u8282\u70b9\u7684\u7c7b\u578b\u662f BinaryTree alpha\uff0c\u8282\u70b9\u7684\u7c7b\u578b\u5219\u662f\u7ed9\u5b9aalpha BinaryTree alpha \u548c BinaryTree alpha \u4e4b\u540e\u5f97\u5230\u7684 BinaryTree alpha\ninductive BinaryTree (\u03b1 : Type)\n  | leaf : BinaryTree \u03b1\n  | node : \u03b1 \u2192 BinaryTree \u03b1 \u2192 BinaryTree \u03b1 \u2192 BinaryTree \u03b1\n\n-- \u8bbe\u7f6e\u4e86\u4e00\u4e2a\u547d\u540d\u7a7a\u95f4\uff0c\u8fd9\u5c31\u610f\u5473\u7740\u6211\u4eec\u5728\u522b\u7684\u5730\u65b9\u8981\u9760open BinaryTree\u6765\u542f\u7528\u8fd9\u4e2a\u5e93\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u5199\u5b8c\u6574\u7f00\nnamespace BinaryTree\n\n-- \u7a7a\u4e8c\u53c9\u6811\ndef empty : BinaryTree \u03b1 := leaf\n\n-- \u8fd9\u91cc\u91c7\u7528\u4e86\u9012\u5f52\u7684\u903b\u8f91\uff0clean4\u5c31\u662f\u4e00\u95e8\u9012\u5f52\u4e3a\u4e3b\u7684\u8bed\u8a00\n-- \u5982\u679c\u5f53\u524d\u8282\u70b9\u662f\u53f6\u5b50\uff0c\u5c31\u5c06\u5f85\u63d2\u5165\u7684\u6570\u636e\u653e\u5728\u53f6\u5b50\u4e0a\uff1b\u5982\u679c\u5f53\u524d\u662f\u8282\u70b9\uff0c\u5c31\u68c0\u67e5\u5f85\u63d2\u5165\u503c\u662f\u5426\u6bd4\u8282\u70b9\u503c\u5927\uff0c\u5982\u679c\u5927\u5c31\u5728\u53f3\u6811\u4e2d\u9012\u5f52\uff0c\u5982\u679c\u5c0f\u5c31\u5728\u5de6\u6811\u4e2d\u9012\u5f52\ndef insert [Ord \u03b1] (x : \u03b1) (t : BinaryTree \u03b1) : BinaryTree \u03b1 :=\n  match t with\n  | leaf =&gt; node x leaf leaf\n  | node y left right =&gt;\n    match compare x y with\n    | .lt =&gt; node y (insert x left) right\n    | .gt =&gt; node y left (insert x right)\n    | .eq =&gt; t\n\n-- \u672c\u8d28\u4e0a\u5c31\u662f\u904d\u5386\u4e8c\u53c9\u6811\ndef contains [Ord \u03b1] (x : \u03b1) (t : BinaryTree \u03b1) : Bool :=\n  match t with\n  | leaf =&gt; false\n  | node y left right =&gt;\n    match compare x y with\n    | .lt =&gt; contains x left\n    | .gt =&gt; contains x right\n    | .eq =&gt; true\n\n-- \u4e2d\u7f00\u8868\u8fbe\u5316\ndef inorder (t : BinaryTree \u03b1) : List \u03b1 :=\n  match t with\n  | leaf =&gt; []\n  | node x left right =&gt; (inorder left) ++ [x] ++ (inorder right)\n\nend BinaryTree\n</code></pre>"},{"location":"Research/How_to_do_survey/","title":"How to do survey","text":""},{"location":"Research/How_to_do_survey/#_1","title":"\u6587\u732e\u8c03\u7814\u6d41\u7a0b\u590d\u76d8","text":"<p>\u603b\u7ed3\u4e00\u4e0b\u8fd9\u6b21\u7684\u7efc\u8ff0\u8c03\u7814\u5177\u4f53\u6d41\u7a0b\u548c\u60f3\u6cd5\u3002</p> <p>\u4e00\u3001 \u7528\u5230\u7684\u5de5\u5177</p> <p>\u4e3b\u8981\u5c31\u662f\u51e0\u4e2a\u7f51\u7ad9\uff0c\u6bcf\u4e2a\u90fd\u6709\u660e\u786e\u7528\u9014\uff1a</p> <ul> <li><code>Connected Papers</code>: \u5f53\u627e\u5230\u4e00\u7bc7\u5173\u952e\u8bba\u6587\u65f6\uff0c\u7528\u5b83\u6765\u770b\u8fd9\u5f20\u8bba\u6587\u7684\u201c\u5173\u7cfb\u7f51\u201d\uff0c\u80fd\u5f88\u5feb\u53d1\u73b0\u4e00\u6279\u9ad8\u5ea6\u76f8\u5173\u7684\u5176\u4ed6\u8bba\u6587\u3002</li> <li><code>GitHub Awesome Lists</code>: \u6709\u65f6\u5019\u60f3\u627e\u67d0\u4e2a\u9886\u57df\u7684\u8d44\u6e90\u6c47\u603b\uff0c\u5c31\u53bbGitHub\u641c\u201cawesome-[\u9886\u57df\u540d]\u201d\uff0c\u7ecf\u5e38\u80fd\u627e\u5230\u597d\u4e1c\u897f\u3002</li> <li><code>Google Scholar</code> / <code>arXiv</code>: \u7528\u6765\u7cbe\u786e\u67e5\u627e\u548c\u4e0b\u8f7d\u5df2\u77e5\u7684\u8bba\u6587\u3002</li> </ul> <p>\u4e8c\u3001 \u5177\u4f53\u7684\u5de5\u4f5c\u6b65\u9aa4</p> <p>\u6574\u4e2a\u8fc7\u7a0b\u53ef\u4ee5\u5206\u6210\u4e24\u4e2a\u9636\u6bb5\u3002</p> <p>\u7b2c\u4e00\u9636\u6bb5\uff1a\u6478\u5e95\u548c\u642d\u6846\u67b6</p> <ol> <li>\u60f3\u6e05\u695a\u95ee\u9898\uff1a\u6700\u5f00\u59cb\uff0c\u5148\u660e\u786e\u8fd9\u6b21\u8c03\u7814\u5230\u5e95\u8981\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\u3002\u6bd4\u5982\u8fd9\u6b21\uff0c\u5c31\u662f\u201c\u73b0\u5728\u5927\u5bb6\u662f\u600e\u4e48\u7528\u5927\u6a21\u578b\u751f\u6210\u6587\u6863\u7684\uff1f\u201d</li> <li>\u627e\u5230\u5173\u952e\u8bba\u6587\uff1a\u57fa\u4e8e\u8fd9\u4e2a\u95ee\u9898\uff0c\u627e\u5230\u4e86\u4e24\u4e09\u7bc7\u7ed5\u4e0d\u5f00\u7684\u6838\u5fc3\u8bba\u6587\u3002\u8fd9\u51e0\u7bc7\u8bba\u6587\u5c31\u662f\u8c03\u7814\u7684\u8d77\u70b9\u3002</li> <li>\u8ba9AI\u5feb\u901f\u8bb2\u89e3\uff1a\u628a\u8fd9\u51e0\u7bc7\u8bba\u6587\u4e22\u7ed9AI\uff0c\u8ba9\u5b83\u5feb\u901f\u8bb2\u8bb2\u6bcf\u7bc7\u7684\u6838\u5fc3\u601d\u60f3\u3001\u7528\u4e86\u4ec0\u4e48\u65b9\u6cd5\u3002\u7136\u540e\u8ba9\u5b83\u5e2e\u5fd9\u7b80\u5355\u5206\u4e2a\u7c7b\uff0c\u6bd4\u5982\u6309\u201c\u6570\u636e\u7c7b\u578b\u3001\u5408\u6210\u65b9\u6cd5\u201d\u505a\u6210\u8868\u683c\u3002\u505a\u5b8c\u8fd9\u6b65\uff0c\u5bf9\u8fd9\u4e2a\u9886\u57df\u5c31\u6709\u4e86\u4e00\u4e2a\u5927\u6982\u7684\u8ba4\u77e5\u6846\u67b6\u3002</li> </ol> <p>\u7b2c\u4e8c\u9636\u6bb5\uff1a\u6574\u7406\u601d\u8def\uff0c\u5199\u6210\u6587\u7a3f</p> <ol> <li>\u8c03\u6574\u601d\u8def\uff1a\u4e00\u5f00\u59cb\u7684\u8868\u683c\u867d\u7136\u6e05\u695a\uff0c\u4f46\u770b\u8d77\u6765\u5f88\u96f6\u6563\uff0c\u8bb2\u4e0d\u51fa\u4e00\u4e2a\u5b8c\u6574\u7684\u6545\u4e8b\u3002\u6240\u4ee5\u51b3\u5b9a\u6362\u4e2a\u601d\u8def\uff0c\u4e0d\u518d\u662f\u7b80\u5355\u7f57\u5217\uff0c\u800c\u662f\u8981\u68b3\u7406\u51fa\u4e00\u6761\u6280\u672f\u53d1\u5c55\u7684\u7ebf\u7d22\u3002</li> <li>\u67e5\u6f0f\u8865\u7f3a\uff1a\u6709\u4e86\u65b0\u7684\u53d9\u4e8b\u7ebf\u7d22\u540e\uff0c\u5c31\u53d1\u73b0\u539f\u6765\u7684\u51e0\u7bc7\u8bba\u6587\u4e0d\u591f\u4e86\u3002\u6bd4\u5982\uff0c\u9664\u4e86\u8bb2\u6838\u5fc3\u65b9\u6cd5\u7684\u8bba\u6587\uff0c\u8fd8\u9700\u8981\u8bb2\u6570\u636e\u96c6\u7684\u3001\u8bb2\u8bc4\u4f30\u65b9\u6cd5\u7684\u8bba\u6587\u6765\u8ba9\u6545\u4e8b\u66f4\u5b8c\u6574\u3002\u8fd9\u65f6\u5c31\u5e26\u7740\u660e\u786e\u7684\u76ee\u6807\u53bb\u627e\u8fd9\u4e9b\u7f3a\u5931\u7684\u73af\u8282\u3002\u8fd9\u6b21\u6211\u63d0\u4f9b\u4e86\u5f88\u591a\u65b0\u7684\u8bba\u6587\u4fe1\u606f\uff0c\u5c31\u662f\u5728\u8fd9\u4e2a\u9636\u6bb5\u3002</li> <li>\u6574\u7406\u6210\u6587\uff1a\u6750\u6599\u90fd\u9f50\u4e86\uff0c\u5c31\u5f00\u59cb\u6574\u7406\u6700\u7ec8\u7684\u6587\u5b57\u3002\u4ece\u6240\u6709\u627e\u5230\u7684\u8bba\u6587\u91cc\uff0c\u6311\u51fa\u6700\u6709\u4ee3\u8868\u6027\u7684\u51e0\u7bc7\uff0c\u786e\u4fdd\u5b83\u4eec\u80fd\u4e32\u8d77\u6574\u4e2a\u6545\u4e8b\uff0c\u5e76\u4e14\u4e92\u76f8\u4e0d\u91cd\u590d\u3002\u7136\u540e\u8ba9AI\u628a\u8fd9\u4e9b\u5185\u5bb9\u548c\u5f15\u7528\u4fe1\u606f\uff0c\u6309\u7167\u5b9a\u597d\u7684\u683c\u5f0f\u5199\u51fa\u6765\u3002</li> </ol> <p>\u4e09\u3001 \u6587\u4ef6\u6574\u7406\u4e60\u60ef</p> <p>\u4e3a\u4e86\u4e0d\u4e71\uff0c\u6587\u4ef6\u5206\u4e86\u51e0\u4e2a\u5730\u65b9\u653e\uff1a</p> <ul> <li>\u4e00\u4e2a\u53eb <code>Document</code> \u6216 <code>Essay_Buffer</code> \u7684\u6587\u4ef6\uff0c\u4e13\u95e8\u653e\u6240\u6709\u539f\u59cb\u7684\u7b14\u8bb0\u3001\u5bf9\u8bdd\u8bb0\u5f55\u548c\u5404\u79cd\u8bba\u6587\u6458\u8981\uff0c\u662f\u4e2a\u8349\u7a3f\u533a\u3002</li> <li>\u4e00\u4e2a <code>Output</code> \u6587\u4ef6\uff0c\u53ea\u653e\u6700\u540e\u6574\u7406\u597d\u7684\u3001\u53ef\u4ee5\u76f4\u63a5\u590d\u5236\u7c98\u8d34\u5230\u6700\u7ec8\u6587\u7a3f\u91cc\u7684\u5185\u5bb9\u3002</li> </ul>"},{"location":"Research/Survey_plan_about_code_llm/","title":"\u4ee3\u7801\u5927\u6a21\u578b\u8bc4\u6d4b\u9886\u57df\u5206\u7c7b","text":""},{"location":"Research/Survey_plan_about_code_llm/#1","title":"1. \u57fa\u7840\u7f16\u7a0b\u80fd\u529b\u8bc4\u6d4b","text":"<ul> <li>HumanEval</li> <li>MBPP </li> <li>LeetCode\u7c7b\u8bc4\u6d4b</li> </ul>"},{"location":"Research/Survey_plan_about_code_llm/#2","title":"2. \u4ee3\u7801\u7406\u89e3\u80fd\u529b\u8bc4\u6d4b","text":"<ul> <li>CodeXGLUE\u4e2d\u7684\u4ee3\u7801\u7406\u89e3\u4efb\u52a1</li> <li>CodeT\u7684\u4e2d\u6587\u4ee3\u7801\u7406\u89e3</li> <li>\u4ee3\u7801\u6ce8\u91ca\u751f\u6210\u8bc4\u6d4b</li> </ul>"},{"location":"Research/Survey_plan_about_code_llm/#3","title":"3. \u4ee3\u7801\u751f\u6210\u80fd\u529b\u8bc4\u6d4b","text":"<ul> <li>Text-to-Code\u751f\u6210</li> <li>\u8865\u5168\u4efb\u52a1\u8bc4\u6d4b</li> <li>\u591a\u8bed\u8a00\u4ee3\u7801\u8f6c\u6362</li> </ul>"},{"location":"Research/Survey_plan_about_code_llm/#4","title":"4. \u4e13\u4e1a\u9886\u57df\u8bc4\u6d4b","text":"<ul> <li>DS-1000(\u6570\u636e\u79d1\u5b66)</li> <li>WebArena(Web\u5f00\u53d1)</li> <li>CTF(\u5b89\u5168\u9886\u57df)</li> </ul>"},{"location":"Research/Survey_plan_about_code_llm/#5","title":"5. \u7efc\u5408\u80fd\u529b\u8bc4\u6d4b","text":"<ul> <li>Big-Code-Bench</li> <li>MultiPL-E</li> <li>CodeContests</li> </ul>"},{"location":"Research/Survey_plan_about_code_llm/#6","title":"6. \u5de5\u7a0b\u5b9e\u8df5\u8bc4\u6d4b","text":"<ul> <li>API\u4f7f\u7528\u8bc4\u6d4b</li> <li>\u4ee3\u7801\u91cd\u6784\u8bc4\u6d4b</li> <li>\u8c03\u8bd5\u4e0e\u4fee\u590d\u8bc4\u6d4b</li> </ul>"},{"location":"SAE/openai_sae_train/","title":"SAE_Train","text":"<p>\u8fd9\u91cc\u7c98\u8d34\u4e00\u4e0bOpenAI\u5728https://github.com/openai/sparse_autoencoder\u5e93\u4e2d\u7684train.py\u6e90\u4ee3\u7801\uff0c\u8fd9\u6bb5\u4ee3\u7801\u91cc\u9762\u7684\u6599\u975e\u5e38\u591a\uff0c\u4e0d\u8fc7\u4e0d\u4fbf\u4e8e\u8fc5\u901f\u7406\u89e3\u5e76\u8fdb\u884c\u90e8\u7f72\uff0c\u6211\u4eec\u4f1a\u6162\u6162\u5b66\u4e60\u5e76\u89e3\u8bfb\uff1a</p> <p><pre><code># bare bones training script using sparse kernels and sharding/data parallel.\n# the main purpose of this code is to provide a reference implementation to compare\n# against when implementing our training methodology into other codebases, and to\n# demonstrate how sharding/DP can be implemented for autoencoders. some limitations:\n# - many basic features (e.g checkpointing, data loading, validation) are not implemented,\n# - the codebase is not designed to be extensible or easily hackable.\n# - this code is not guaranteed to run efficiently out of the box / in\n#   combination with other changes, so you should profile it and make changes as needed.\n#\n# example launch command:\n#    torchrun --nproc-per-node 8 train.py\n\n\nimport os\nfrom dataclasses import dataclass\nfrom typing import Callable, Iterable, Iterator\n\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport triton\nimport triton.language as tl\nfrom sparse_autoencoder.kernels import *\nfrom torch.distributed import ReduceOp\n\nRANK = int(os.environ.get(\"RANK\", \"0\"))\n\n\n## parallelism\n\n\n@dataclass\nclass Comm:\n    group: torch.distributed.ProcessGroup\n\n    def all_reduce(self, x, op=ReduceOp.SUM, async_op=False):\n        return dist.all_reduce(x, op=op, group=self.group, async_op=async_op)\n\n    def all_gather(self, x_list, x, async_op=False):\n        return dist.all_gather(list(x_list), x, group=self.group, async_op=async_op)\n\n    def broadcast(self, x, src, async_op=False):\n        return dist.broadcast(x, src, group=self.group, async_op=async_op)\n\n    def barrier(self):\n        return dist.barrier(group=self.group)\n\n    def size(self):\n        return self.group.size()\n\n\n@dataclass\nclass ShardingComms:\n    n_replicas: int\n    n_op_shards: int\n    dp_rank: int\n    sh_rank: int\n    dp_comm: Comm | None\n    sh_comm: Comm | None\n    _rank: int\n\n    def sh_allreduce_forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        if self.sh_comm is None:\n            return x\n\n        class AllreduceForward(torch.autograd.Function):\n            @staticmethod\n            def forward(ctx, input):\n                assert self.sh_comm is not None\n                self.sh_comm.all_reduce(input, async_op=True)\n                return input\n\n            @staticmethod\n            def backward(ctx, grad_output):\n                return grad_output\n\n        return AllreduceForward.apply(x)  # type: ignore\n\n    def sh_allreduce_backward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        if self.sh_comm is None:\n            return x\n\n        class AllreduceBackward(torch.autograd.Function):\n            @staticmethod\n            def forward(ctx, input):\n                return input\n\n            @staticmethod\n            def backward(ctx, grad_output):\n                grad_output = grad_output.clone()\n                assert self.sh_comm is not None\n                self.sh_comm.all_reduce(grad_output, async_op=True)\n                return grad_output\n\n        return AllreduceBackward.apply(x)  # type: ignore\n\n    def init_broadcast_(self, autoencoder):\n        if self.dp_comm is not None:\n            for p in autoencoder.parameters():\n                self.dp_comm.broadcast(\n                    maybe_transpose(p.data),\n                    replica_shard_to_rank(\n                        replica_idx=0,\n                        shard_idx=self.sh_rank,\n                        n_op_shards=self.n_op_shards,\n                    ),\n                )\n\n        if self.sh_comm is not None:\n            # pre_bias is the same across all shards\n            self.sh_comm.broadcast(\n                autoencoder.pre_bias.data,\n                replica_shard_to_rank(\n                    replica_idx=self.dp_rank,\n                    shard_idx=0,\n                    n_op_shards=self.n_op_shards,\n                ),\n            )\n\n    def dp_allreduce_(self, autoencoder) -&gt; None:\n        if self.dp_comm is None:\n            return\n\n        for param in autoencoder.parameters():\n            if param.grad is not None:\n                self.dp_comm.all_reduce(maybe_transpose(param.grad), op=ReduceOp.AVG, async_op=True)\n\n        # make sure statistics for dead neurons are correct\n        self.dp_comm.all_reduce(  # type: ignore\n            autoencoder.stats_last_nonzero, op=ReduceOp.MIN, async_op=True\n        )\n\n    def sh_allreduce_scale(self, scaler):\n        if self.sh_comm is None:\n            return\n\n        if hasattr(scaler, \"_scale\") and scaler._scale is not None:\n            self.sh_comm.all_reduce(scaler._scale, op=ReduceOp.MIN, async_op=True)\n            self.sh_comm.all_reduce(scaler._growth_tracker, op=ReduceOp.MIN, async_op=True)\n\n    def _sh_comm_op(self, x, op):\n        if isinstance(x, (float, int)):\n            x = torch.tensor(x, device=\"cuda\")\n\n        if not x.is_cuda:\n            x = x.cuda()\n\n        if self.sh_comm is None:\n            return x\n\n        out = x.clone()\n        self.sh_comm.all_reduce(x, op=op, async_op=True)\n        return out\n\n    def sh_sum(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self._sh_comm_op(x, ReduceOp.SUM)\n\n    def all_broadcast(self, x: torch.Tensor) -&gt; torch.Tensor:\n        if self.dp_comm is not None:\n            self.dp_comm.broadcast(\n                x,\n                replica_shard_to_rank(\n                    replica_idx=0,\n                    shard_idx=self.sh_rank,\n                    n_op_shards=self.n_op_shards,\n                ),\n            )\n\n        if self.sh_comm is not None:\n            self.sh_comm.broadcast(\n                x,\n                replica_shard_to_rank(\n                    replica_idx=self.dp_rank,\n                    shard_idx=0,\n                    n_op_shards=self.n_op_shards,\n                ),\n            )\n\n        return x\n\n\ndef make_torch_comms(n_op_shards=4, n_replicas=2):\n    if \"RANK\" not in os.environ:\n        assert n_op_shards == 1\n        assert n_replicas == 1\n        return TRIVIAL_COMMS\n\n    rank = int(os.environ.get(\"RANK\"))\n    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(rank % 8)\n\n    print(f\"{rank=}, {world_size=}\")\n    dist.init_process_group(\"nccl\")\n\n    my_op_shard_idx = rank % n_op_shards\n    my_replica_idx = rank // n_op_shards\n\n    shard_rank_lists = [list(range(i, i + n_op_shards)) for i in range(0, world_size, n_op_shards)]\n\n    shard_groups = [dist.new_group(shard_rank_list) for shard_rank_list in shard_rank_lists]\n\n    my_shard_group = shard_groups[my_replica_idx]\n\n    replica_rank_lists = [\n        list(range(i, n_op_shards * n_replicas, n_op_shards)) for i in range(n_op_shards)\n    ]\n\n    replica_groups = [dist.new_group(replica_rank_list) for replica_rank_list in replica_rank_lists]\n\n    my_replica_group = replica_groups[my_op_shard_idx]\n\n    torch.distributed.all_reduce(torch.ones(1).cuda())\n    torch.cuda.synchronize()\n\n    dp_comm = Comm(group=my_replica_group)\n    sh_comm = Comm(group=my_shard_group)\n\n    return ShardingComms(\n        n_replicas=n_replicas,\n        n_op_shards=n_op_shards,\n        dp_comm=dp_comm,\n        sh_comm=sh_comm,\n        dp_rank=my_replica_idx,\n        sh_rank=my_op_shard_idx,\n        _rank=rank,\n    )\n\n\ndef replica_shard_to_rank(replica_idx, shard_idx, n_op_shards):\n    return replica_idx * n_op_shards + shard_idx\n\n\nTRIVIAL_COMMS = ShardingComms(\n    n_replicas=1,\n    n_op_shards=1,\n    dp_rank=0,\n    sh_rank=0,\n    dp_comm=None,\n    sh_comm=None,\n    _rank=0,\n)\n\n\ndef sharded_topk(x, k, sh_comm, capacity_factor=None):\n    batch = x.shape[0]\n\n    if capacity_factor is not None:\n        k_in = min(int(k * capacity_factor // sh_comm.size()), k)\n    else:\n        k_in = k\n\n    topk = torch.topk(x, k=k_in, dim=-1)\n    inds = topk.indices\n    vals = topk.values\n\n    if sh_comm is None:\n        return inds, vals\n\n    all_vals = torch.empty(sh_comm.size(), batch, k_in, dtype=vals.dtype, device=vals.device)\n    sh_comm.all_gather(all_vals, vals, async_op=True)\n\n    all_vals = all_vals.permute(1, 0, 2)  # put shard dim next to k\n    all_vals = all_vals.reshape(batch, -1)  # flatten shard into k\n\n    all_topk = torch.topk(all_vals, k=k, dim=-1)\n    global_topk = all_topk.values\n\n    dummy_vals = torch.zeros_like(vals)\n    dummy_inds = torch.zeros_like(inds)\n\n    my_inds = torch.where(vals &gt;= global_topk[:, [-1]], inds, dummy_inds)\n    my_vals = torch.where(vals &gt;= global_topk[:, [-1]], vals, dummy_vals)\n\n    return my_inds, my_vals\n\n\n## autoencoder\n\n\nclass FastAutoencoder(nn.Module):\n    \"\"\"\n    Top-K Autoencoder with sparse kernels. Implements:\n\n        latents = relu(topk(encoder(x - pre_bias) + latent_bias))\n        recons = decoder(latents) + pre_bias\n    \"\"\"\n\n    def __init__(\n        self,\n        n_dirs_local: int,\n        d_model: int,\n        k: int,\n        auxk: int | None,\n        dead_steps_threshold: int,\n        comms: ShardingComms | None = None,\n    ):\n        super().__init__()\n        self.n_dirs_local = n_dirs_local\n        self.d_model = d_model\n        self.k = k\n        self.auxk = auxk\n        self.comms = comms if comms is not None else TRIVIAL_COMMS\n        self.dead_steps_threshold = dead_steps_threshold\n\n        self.encoder = nn.Linear(d_model, n_dirs_local, bias=False)\n        self.decoder = nn.Linear(n_dirs_local, d_model, bias=False)\n\n        self.pre_bias = nn.Parameter(torch.zeros(d_model))\n        self.latent_bias = nn.Parameter(torch.zeros(n_dirs_local))\n\n        self.stats_last_nonzero: torch.Tensor\n        self.register_buffer(\"stats_last_nonzero\", torch.zeros(n_dirs_local, dtype=torch.long))\n\n        def auxk_mask_fn(x):\n            dead_mask = self.stats_last_nonzero &gt; dead_steps_threshold\n            x.data *= dead_mask  # inplace to save memory\n            return x\n\n        self.auxk_mask_fn = auxk_mask_fn\n\n        ## initialization\n\n        # \"tied\" init\n        self.decoder.weight.data = self.encoder.weight.data.T.clone()\n\n        # store decoder in column major layout for kernel\n        self.decoder.weight.data = self.decoder.weight.data.T.contiguous().T\n\n        unit_norm_decoder_(self)\n\n    @property\n    def n_dirs(self):\n        return self.n_dirs_local * self.comms.n_op_shards\n\n    def forward(self, x):\n        class EncWrapper(torch.autograd.Function):\n            @staticmethod\n            def forward(ctx, x, pre_bias, weight, latent_bias):\n                x = x - pre_bias\n                latents_pre_act = F.linear(x, weight, latent_bias)\n\n                inds, vals = sharded_topk(\n                    latents_pre_act,\n                    k=self.k,\n                    sh_comm=self.comms.sh_comm,\n                    capacity_factor=4,\n                )\n\n                ## set num nonzero stat ##\n                tmp = torch.zeros_like(self.stats_last_nonzero)\n                tmp.scatter_add_(\n                    0,\n                    inds.reshape(-1),\n                    (vals &gt; 1e-3).to(tmp.dtype).reshape(-1),\n                )\n                self.stats_last_nonzero *= 1 - tmp.clamp(max=1)\n                self.stats_last_nonzero += 1\n                ## end stats ##\n\n                ## auxk\n                if self.auxk is not None:  # for auxk\n                    # IMPORTANT: has to go after stats update!\n                    # WARN: auxk_mask_fn can mutate latents_pre_act!\n                    auxk_inds, auxk_vals = sharded_topk(\n                        self.auxk_mask_fn(latents_pre_act),\n                        k=self.auxk,\n                        sh_comm=self.comms.sh_comm,\n                        capacity_factor=2,\n                    )\n                    ctx.save_for_backward(x, weight, inds, auxk_inds)\n                else:\n                    ctx.save_for_backward(x, weight, inds)\n                    auxk_inds = None\n                    auxk_vals = None\n\n                ## end auxk\n\n                return (\n                    inds,\n                    vals,\n                    auxk_inds,\n                    auxk_vals,\n                )\n\n            @staticmethod\n            def backward(ctx, _, grad_vals, __, grad_auxk_vals):\n                # encoder backwards\n                if self.auxk is not None:\n                    x, weight, inds, auxk_inds = ctx.saved_tensors\n\n                    all_inds = torch.cat((inds, auxk_inds), dim=-1)\n                    all_grad_vals = torch.cat((grad_vals, grad_auxk_vals), dim=-1)\n                else:\n                    x, weight, inds = ctx.saved_tensors\n\n                    all_inds = inds\n                    all_grad_vals = grad_vals\n\n                grad_sum = torch.zeros(self.n_dirs_local, dtype=torch.float32, device=grad_vals.device)\n                grad_sum.scatter_add_(\n                    -1, all_inds.flatten(), all_grad_vals.flatten().to(torch.float32)\n                )\n\n                return (\n                    None,\n                    # pre_bias grad optimization - can reduce before mat-vec multiply\n                    -(grad_sum @ weight),\n                    triton_sparse_transpose_dense_matmul(all_inds, all_grad_vals, x, N=self.n_dirs_local),\n                    grad_sum,\n                )\n\n        pre_bias = self.comms.sh_allreduce_backward(self.pre_bias)\n\n        # encoder\n        inds, vals, auxk_inds, auxk_vals = EncWrapper.apply(\n            x, pre_bias, self.encoder.weight, self.latent_bias\n        )\n\n        vals = torch.relu(vals)\n        if auxk_vals is not None:\n            auxk_vals = torch.relu(auxk_vals)\n\n        recons = self.decode_sparse(inds, vals)\n\n        return recons, {\n            \"auxk_inds\": auxk_inds,\n            \"auxk_vals\": auxk_vals,\n        }\n\n    def decode_sparse(self, inds, vals):\n        recons = TritonDecoderAutograd.apply(inds, vals, self.decoder.weight)\n        recons = self.comms.sh_allreduce_forward(recons)\n\n        return recons + self.pre_bias\n\n\ndef unit_norm_decoder_(autoencoder: FastAutoencoder) -&gt; None:\n    \"\"\"\n    Unit normalize the decoder weights of an autoencoder.\n    \"\"\"\n    autoencoder.decoder.weight.data /= autoencoder.decoder.weight.data.norm(dim=0)\n\n\ndef unit_norm_decoder_grad_adjustment_(autoencoder) -&gt; None:\n    \"\"\"project out gradient information parallel to the dictionary vectors - assumes that the decoder is already unit normed\"\"\"\n\n    assert autoencoder.decoder.weight.grad is not None\n\n    triton_add_mul_(\n        autoencoder.decoder.weight.grad,\n        torch.einsum(\"bn,bn-&gt;n\", autoencoder.decoder.weight.data, autoencoder.decoder.weight.grad),\n        autoencoder.decoder.weight.data,\n        c=-1,\n    )\n\n\ndef maybe_transpose(x):\n    return x.T if not x.is_contiguous() and x.T.is_contiguous() else x\n\n\ndef sharded_grad_norm(autoencoder, comms, exclude=None):\n    if exclude is None:\n        exclude = []\n    total_sq_norm = torch.zeros((), device=\"cuda\", dtype=torch.float32)\n    exclude = set(exclude)\n\n    total_num_params = 0\n    for param in autoencoder.parameters():\n        if param in exclude:\n            continue\n        if param.grad is not None:\n            sq_norm = ((param.grad).float() ** 2).sum()\n            if param is autoencoder.pre_bias:\n                total_sq_norm += sq_norm  # pre_bias is the same across all shards\n            else:\n                total_sq_norm += comms.sh_sum(sq_norm)\n\n            param_shards = comms.n_op_shards if param is autoencoder.pre_bias else 1\n            total_num_params += param.numel() * param_shards\n\n    return total_sq_norm.sqrt()\n\n\ndef batch_tensors(\n    it: Iterable[torch.Tensor],\n    batch_size: int,\n    drop_last=True,\n    stream=None,\n) -&gt; Iterator[torch.Tensor]:\n    \"\"\"\n    input is iterable of tensors of shape [batch_old, ...]\n    output is iterable of tensors of shape [batch_size, ...]\n    batch_old does not need to be divisible by batch_size\n    \"\"\"\n\n    tensors = []\n    batch_so_far = 0\n\n    for t in it:\n        tensors.append(t)\n        batch_so_far += t.shape[0]\n\n        if sum(t.shape[0] for t in tensors) &lt; batch_size:\n            continue\n\n        while batch_so_far &gt;= batch_size:\n            if len(tensors) == 1:\n                (concat,) = tensors\n            else:\n                with torch.cuda.stream(stream):\n                    concat = torch.cat(tensors, dim=0)\n\n            offset = 0\n            while offset + batch_size &lt;= concat.shape[0]:\n                yield concat[offset : offset + batch_size]\n                batch_so_far -= batch_size\n                offset += batch_size\n\n            tensors = [concat[offset:]] if offset &lt; concat.shape[0] else []\n\n    if len(tensors) &gt; 0 and not drop_last:\n        yield torch.cat(tensors, dim=0)\n\n\ndef print0(*a, **k):\n    if RANK == 0:\n        print(*a, **k)\n\n\nimport wandb\n\n\nclass Logger:\n    def __init__(self, **kws):\n        self.vals = {}\n        self.enabled = (RANK == 0) and not kws.pop(\"dummy\", False)\n        if self.enabled:\n            wandb.init(\n                **kws\n            )\n\n    def logkv(self, k, v):\n        if self.enabled:\n            self.vals[k] = v.detach() if isinstance(v, torch.Tensor) else v\n        return v\n\n    def dumpkvs(self):\n        if self.enabled:\n            wandb.log(self.vals)\n            self.vals = {}\n\n\ndef training_loop_(\n    ae, train_acts_iter, loss_fn, lr, comms, eps=6.25e-10, clip_grad=None, ema_multiplier=0.999, logger=None\n):\n    if logger is None:\n        logger = Logger(dummy=True)\n\n    scaler = torch.cuda.amp.GradScaler()\n    autocast_ctx_manager = torch.cuda.amp.autocast()\n\n    opt = torch.optim.Adam(ae.parameters(), lr=lr, eps=eps, fused=True)\n    if ema_multiplier is not None:\n        ema = EmaModel(ae, ema_multiplier=ema_multiplier)\n\n    for i, flat_acts_train_batch in enumerate(train_acts_iter):\n        flat_acts_train_batch = flat_acts_train_batch.cuda()\n\n        with autocast_ctx_manager:\n            recons, info = ae(flat_acts_train_batch)\n\n            loss = loss_fn(ae, flat_acts_train_batch, recons, info, logger)\n\n        print0(i, loss)\n\n        logger.logkv(\"loss_scale\", scaler.get_scale())\n\n        if RANK == 0:\n            wandb.log({\"train_loss\": loss.item()})\n\n        loss = scaler.scale(loss)\n        loss.backward()\n\n        unit_norm_decoder_(ae)\n        unit_norm_decoder_grad_adjustment_(ae)\n\n        # allreduce gradients\n        comms.dp_allreduce_(ae)\n\n        # keep fp16 loss scale synchronized across shards\n        comms.sh_allreduce_scale(scaler)\n\n        # if you want to do anything with the gradients that depends on the absolute scale (e.g clipping, do it after the unscale_)\n        scaler.unscale_(opt)\n\n        # gradient clipping\n        if clip_grad is not None:\n            grad_norm = sharded_grad_norm(ae, comms)\n            logger.logkv(\"grad_norm\", grad_norm)\n            grads = [x.grad for x in ae.parameters() if x.grad is not None]\n            torch._foreach_mul_(grads, clip_grad / torch.clamp(grad_norm, min=clip_grad))\n\n        if ema_multiplier is not None:\n            ema.step()\n\n        # take step with optimizer\n        scaler.step(opt)\n        scaler.update()\n\n        logger.dumpkvs()\n\n\ndef init_from_data_(ae, stats_acts_sample, comms):\n    from geom_median.torch import compute_geometric_median\n\n    ae.pre_bias.data = (\n        compute_geometric_median(stats_acts_sample[:32768].float().cpu()).median.cuda().float()\n    )\n    comms.all_broadcast(ae.pre_bias.data)\n\n    # encoder initialization (note: in our ablations we couldn't find clear evidence that this is beneficial, this is just to ensure exact match with internal codebase)\n    d_model = ae.d_model\n    with torch.no_grad():\n        x = torch.randn(256, d_model).cuda().to(stats_acts_sample.dtype)\n        x /= x.norm(dim=-1, keepdim=True)\n        x += ae.pre_bias.data\n        comms.all_broadcast(x)\n        recons, _ = ae(x)\n        recons_norm = (recons - ae.pre_bias.data).norm(dim=-1).mean()\n\n        ae.encoder.weight.data /= recons_norm.item()\n        print0(\"x norm\", x.norm(dim=-1).mean().item())\n        print0(\"out norm\", (ae(x)[0] - ae.pre_bias.data).norm(dim=-1).mean().item())\n\n\nfrom contextlib import contextmanager\n\n\n@contextmanager\ndef temporary_weight_swap(model: torch.nn.Module, new_weights: list[torch.Tensor]):\n    for _p, new_p in zip(model.parameters(), new_weights, strict=True):\n        assert _p.shape == new_p.shape\n        _p.data, new_p.data = new_p.data, _p.data\n\n    yield\n\n    for _p, new_p in zip(model.parameters(), new_weights, strict=True):\n        assert _p.shape == new_p.shape\n        _p.data, new_p.data = new_p.data, _p.data\n\n\nclass EmaModel:\n    def __init__(self, model, ema_multiplier):\n        self.model = model\n        self.ema_multiplier = ema_multiplier\n        self.ema_weights = [torch.zeros_like(x, requires_grad=False) for x in model.parameters()]\n        self.ema_steps = 0\n\n    def step(self):\n        torch._foreach_lerp_(\n            self.ema_weights,\n            list(self.model.parameters()),\n            1 - self.ema_multiplier,\n        )\n        self.ema_steps += 1\n\n    # context manager for setting the autoencoder weights to the EMA weights\n    @contextmanager\n    def use_ema_weights(self):\n        assert self.ema_steps &gt; 0\n\n        # apply bias correction\n        bias_correction = 1 - self.ema_multiplier**self.ema_steps\n        ema_weights_bias_corrected = torch._foreach_div(self.ema_weights, bias_correction)\n\n        with torch.no_grad():\n            with temporary_weight_swap(self.model, ema_weights_bias_corrected):\n                yield\n\n\n@dataclass\nclass Config:\n    n_op_shards: int = 1\n    n_replicas: int = 8\n\n    n_dirs: int = 32768\n    bs: int = 131072\n    d_model: int = 768\n    k: int = 32\n    auxk: int = 256\n\n    lr: float = 1e-4\n    eps: float = 6.25e-10\n    clip_grad: float | None = None\n    auxk_coef: float = 1 / 32\n    dead_toks_threshold: int = 10_000_000\n    ema_multiplier: float | None = None\n\n    wandb_project: str | None = None\n    wandb_name: str | None = None\n\n\ndef main():\n    cfg = Config()\n    comms = make_torch_comms(n_op_shards=cfg.n_op_shards, n_replicas=cfg.n_replicas)\n\n    ## dataloading is left as an exercise for the reader\n    acts_iter = ...\n    stats_acts_sample = ...\n\n    n_dirs_local = cfg.n_dirs // cfg.n_op_shards\n    bs_local = cfg.bs // cfg.n_replicas\n\n    ae = FastAutoencoder(\n        n_dirs_local=n_dirs_local,\n        d_model=cfg.d_model,\n        k=cfg.k,\n        auxk=cfg.auxk,\n        dead_steps_threshold=cfg.dead_toks_threshold // cfg.bs,\n        comms=comms,\n    )\n    ae.cuda()\n    init_from_data_(ae, stats_acts_sample, comms)\n    # IMPORTANT: make sure all DP ranks have the same params\n    comms.init_broadcast_(ae)\n\n    mse_scale = (\n        1 / ((stats_acts_sample.float().mean(dim=0) - stats_acts_sample.float()) ** 2).mean()\n    )\n    comms.all_broadcast(mse_scale)\n    mse_scale = mse_scale.item()\n\n    logger = Logger(\n        project=cfg.wandb_project,\n        name=cfg.wandb_name,\n        dummy=cfg.wandb_project is None,\n    )\n\n    training_loop_(\n        ae,\n        batch_tensors(\n            acts_iter,\n            bs_local,\n            drop_last=True,\n        ),\n        lambda ae, flat_acts_train_batch, recons, info, logger: (\n            # MSE\n            logger.logkv(\"train_recons\", mse_scale * mse(recons, flat_acts_train_batch))\n            # AuxK\n            + logger.logkv(\n                \"train_maxk_recons\",\n                cfg.auxk_coef\n                * normalized_mse(\n                    ae.decode_sparse(\n                        info[\"auxk_inds\"],\n                        info[\"auxk_vals\"],\n                    ),\n                    flat_acts_train_batch - recons.detach() + ae.pre_bias.detach(),\n                ).nan_to_num(0),\n            )\n        ),\n        lr=cfg.lr,\n        eps=cfg.eps,\n        clip_grad=cfg.clip_grad,\n        ema_multiplier=cfg.ema_multiplier,\n        logger=logger,\n        comms=comms,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> \u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u7b80\u5316\u7248\u7684\u8bad\u7ec3\u4ee3\u7801\uff0c\u629b\u5f03\u4e86\u5176\u4e2d\u6240\u6709\u7684\u5206\u5e03\u5f0f\u8fd0\u884c\u3001\u9ad8\u6548\u8bad\u7ec3\u548c\u6a21\u578b\u5e73\u6ed1\u64cd\u4f5c\uff0c\u5e76\u8865\u5145\u4e86\u5176\u4e2d\u7684\u6570\u636e\u8bad\u7ec3\u7c7b\uff1a <pre><code># sparse_autoencoder/my_train.py\n\nimport os\nimport torch\nimport torch.nn as nn\nimport h5py\nimport wandb\nfrom dataclasses import dataclass\nfrom typing import Iterable, Iterator\nfrom tqdm import tqdm\n\n# \u5173\u952e\u4fee\u6539\uff1a\u4f7f\u7528\u76f8\u5bf9\u5bfc\u5165\uff0c\u4ece\u5f53\u524d\u5305\u4e2d\u5bfc\u5165\u5176\u4ed6\u6a21\u5757\n# \u5047\u8bbe FastAutoencoder \u7b49\u6838\u5fc3\u903b\u8f91\u5df2\u7ecf\u5305\u542b\u5728\u672c\u6587\u4ef6\u4e2d\n# \u5982\u679c\u9700\u8981\u4ece\u5176\u4ed6\u6587\u4ef6\u5bfc\u5165\uff0c\u4f8b\u5982 model.py, \u53ef\u4ee5\u7528 from .model import Autoencoder\n\n# ==============================================================================\n# 1. \u4ece sparse_autoencoder/train.py \u590d\u5236\u7684\u6838\u5fc3\u4ee3\u7801 (\u5df2\u6062\u590dAuxK\u903b\u8f91)\n# ==============================================================================\n\n# --- \u5e76\u884c\u901a\u4fe1\u7b80\u5316 ---\n@dataclass\nclass ShardingComms:\n    def sh_allreduce_forward(self, x): return x\n    def sh_allreduce_backward(self, x): return x\n    def init_broadcast_(self, autoencoder): pass\n    def dp_allreduce_(self, autoencoder): pass\n    def sh_allreduce_scale(self, scaler): pass\n    def sh_sum(self, x): return x\n    def all_broadcast(self, x): return x\n\nTRIVIAL_COMMS = ShardingComms()\n\n# --- Autoencoder \u6a21\u578b (\u6062\u590d\u4e86AuxK\u903b\u8f91) ---\nclass FastAutoencoder(nn.Module):\n    def __init__(self, n_dirs_local, d_model, k, auxk, dead_steps_threshold, comms):\n        super().__init__()\n        self.n_dirs_local = n_dirs_local\n        self.d_model = d_model\n        self.k = k\n        self.auxk = auxk\n        self.comms = comms\n        self.dead_steps_threshold = dead_steps_threshold\n\n        self.encoder = nn.Linear(d_model, n_dirs_local, bias=False)\n        self.decoder = nn.Linear(n_dirs_local, d_model, bias=False)\n        self.pre_bias = nn.Parameter(torch.zeros(d_model))\n        self.latent_bias = nn.Parameter(torch.zeros(n_dirs_local))\n\n        self.register_buffer(\"stats_last_nonzero\", torch.zeros(n_dirs_local, dtype=torch.long))\n\n        self.decoder.weight.data = self.encoder.weight.data.T.clone()\n        unit_norm_decoder_(self)\n\n    def auxk_mask_fn(self, x):\n        # \u6a21\u62df\u539f\u59cb\u4ee3\u7801\u4e2d\u7684dead_mask\u903b\u8f91\n        dead_mask = (self.stats_last_nonzero &gt; self.dead_steps_threshold).float()\n        x = x * dead_mask # \u4e58\u4ee50\u62161\n        return x\n\n    def forward(self, x):\n        x_centered = x - self.pre_bias\n        latents_pre_act = nn.functional.linear(x_centered, self.encoder.weight, self.latent_bias)\n\n        # TopK for main loss\n        vals, inds = torch.topk(latents_pre_act, self.k, dim=-1)\n\n        # \u66f4\u65b0\u795e\u7ecf\u5143\u6d3b\u8dc3\u5ea6\u7edf\u8ba1\n        tmp = torch.zeros_like(self.stats_last_nonzero)\n        tmp.scatter_add_(0, inds.reshape(-1), (vals &gt; 1e-3).to(tmp.dtype).reshape(-1))\n        self.stats_last_nonzero *= (1 - tmp.clamp(max=1))\n        self.stats_last_nonzero += 1\n\n        # TopK for AuxK loss\n        auxk_vals, auxk_inds = None, None\n        if self.auxk is not None:\n            masked_latents = self.auxk_mask_fn(latents_pre_act.clone()) # clone to avoid in-place modification issues\n            auxk_vals, auxk_inds = torch.topk(masked_latents, self.auxk, dim=-1)\n\n        latents = torch.relu(vals)\n        recons = self.decode_sparse(inds, latents)\n\n        info = {\n            \"auxk_inds\": auxk_inds,\n            \"auxk_vals\": torch.relu(auxk_vals) if auxk_vals is not None else None,\n        }\n\n        return recons + self.pre_bias, info\n\n    def decode_sparse(self, inds, vals):\n        recons = torch.zeros(inds.shape[0], self.n_dirs_local, device=inds.device, dtype=vals.dtype)\n        recons.scatter_(1, inds, vals)\n        return self.decoder(recons)\n\ndef unit_norm_decoder_(autoencoder):\n    autoencoder.decoder.weight.data /= autoencoder.decoder.weight.data.norm(dim=0, keepdim=True)\n\ndef unit_norm_decoder_grad_adjustment_(autoencoder):\n    if autoencoder.decoder.weight.grad is None: return\n    grad = autoencoder.decoder.weight.grad\n    proj = torch.einsum(\"ij,ij-&gt;j\", grad, autoencoder.decoder.weight.data)\n    autoencoder.decoder.weight.grad -= proj * autoencoder.decoder.weight.data\n\nclass Logger:\n    def __init__(self, **kws):\n        self.vals = {}\n        self.enabled = not kws.pop(\"dummy\", False)\n        if self.enabled:\n            wandb.init(**kws)\n\n    def logkv(self, k, v):\n        if self.enabled:\n            self.vals[k] = v.detach().item() if isinstance(v, torch.Tensor) else v\n        return v\n\n    def dumpkvs(self):\n        if self.enabled:\n            wandb.log(self.vals)\n            self.vals = {}\n\ndef training_loop_(ae, train_acts_iter, loss_fn, lr, comms, eps, clip_grad, logger):\n    opt = torch.optim.Adam(ae.parameters(), lr=lr, eps=eps, fused=True)\n\n    for i, flat_acts_train_batch in enumerate(tqdm(train_acts_iter, desc=\"Training\")):\n        flat_acts_train_batch = flat_acts_train_batch.cuda()\n\n        recons, info = ae(flat_acts_train_batch)\n        loss = loss_fn(ae, flat_acts_train_batch, recons, info, logger)\n\n        loss.backward()\n        unit_norm_decoder_grad_adjustment_(ae)\n\n        if clip_grad is not None:\n            torch.nn.utils.clip_grad_norm_(ae.parameters(), clip_grad)\n\n        opt.step()\n        opt.zero_grad()\n        unit_norm_decoder_(ae)\n\n        logger.dumpkvs()\n\ndef batch_tensors(it: Iterable[torch.Tensor], batch_size: int) -&gt; Iterator[torch.Tensor]:\n    buffer = []\n    current_size = 0\n    for t in it:\n        buffer.append(t)\n        current_size += t.shape[0]\n        while current_size &gt;= batch_size:\n            concatenated = torch.cat(buffer, dim=0)\n            yield concatenated[:batch_size]\n            buffer = [concatenated[batch_size:]]\n            current_size -= batch_size\n    if buffer and buffer[0].shape[0] &gt; 0:\n        yield torch.cat(buffer, dim=0)\n\ndef init_from_data_(ae, stats_acts_sample):\n    # \u68c0\u67e5 geom_median \u662f\u5426\u5df2\u5b89\u88c5\n    try:\n        from geom_median.torch import compute_geometric_median\n        median = compute_geometric_median(stats_acts_sample.float().cpu()).median.cuda().float()\n        ae.pre_bias.data = median\n    except ImportError:\n        print(\"WARNING: 'geom_median' not found. Initializing pre_bias with mean instead.\")\n        median = stats_acts_sample.float().mean(dim=0).cuda()\n        ae.pre_bias.data = median\n\n\n# ==============================================================================\n# 2. \u6211\u4eec\u81ea\u5df1\u5b9e\u73b0\u7684\u3001\u9488\u5bf9HDF5\u7684\u6570\u636e\u52a0\u8f7d\u903b\u8f91\n# ==============================================================================\ndef create_h5_act_iterator(h5_path: str, d_model: int) -&gt; Iterator[torch.Tensor]:\n    print(f\"INFO: \u5f00\u59cb\u4ece {h5_path} \u6d41\u5f0f\u52a0\u8f7d\u6fc0\u6d3b\u503c...\")\n    with h5py.File(h5_path, 'r') as f:\n        dset = f['hidden_states']\n        num_sequences = dset.shape[0]\n\n        for i in range(num_sequences):\n            seq_block = torch.from_numpy(dset[i, :, :])\n            yield seq_block.reshape(-1, d_model)\n\ndef get_stats_sample(h5_path: str, num_samples: int) -&gt; torch.Tensor:\n    print(f\"INFO: \u4ece {h5_path} \u63d0\u53d6 {num_samples} \u4e2a\u6837\u672c\u7528\u4e8e\u521d\u59cb\u5316...\")\n    samples = []\n    num_collected = 0\n    with h5py.File(h5_path, 'r') as f:\n        dset = f['hidden_states']\n        for i in range(dset.shape[0]):\n            seq_block = torch.from_numpy(dset[i, :, :])\n            samples.append(seq_block.reshape(-1, dset.shape[2]))\n            num_collected += samples[-1].shape[0]\n            if num_collected &gt;= num_samples:\n                break\n    return torch.cat(samples, dim=0)[:num_samples]\n\n# ==============================================================================\n# 3. \u4e3b\u7a0b\u5e8f\uff1a\u914d\u7f6e\u5e76\u542f\u52a8\u8bad\u7ec3\n# ==============================================================================\n@dataclass\nclass Config:\n    # \u4e0e\u539f\u59cbtrain.py\u4fdd\u6301\u4e00\u81f4\n    h5_path: str = \"/data0/yfliu/vqhlm/datasets/wikitext103_gpt2finetuned/train.h5\"\n    d_model: int = 768\n    n_dirs: int = 32768\n    bs: int = 4096 # token-level batch size\n    k: int = 32\n    auxk: int = 256\n    auxk_coef: float = 1 / 32\n    lr: float = 1e-4\n    eps: float = 1e-8\n    clip_grad: float | None = 1.0\n    dead_toks_threshold: int = 10_000_000\n    wandb_project: str = \"sparse-autoencoder-full-logic\"\n    wandb_name: str | None = \"gpt2-h5-resid-post-exp1-full\"\n    # \u65b0\u589e\uff1a\u4fdd\u5b58\u6a21\u578b\u7684\u76ee\u5f55\n    save_dir: str = \"saved_models\"\n\ndef normalized_mse(y_hat, y):\n    return (y_hat - y).pow(2).sum() / y.pow(2).sum()\n\ndef main():\n    cfg = Config()\n    comms = TRIVIAL_COMMS\n\n    acts_iter = create_h5_act_iterator(cfg.h5_path, cfg.d_model)\n    stats_acts_sample = get_stats_sample(cfg.h5_path, num_samples=65536).cuda()\n\n    ae = FastAutoencoder(\n        n_dirs_local=cfg.n_dirs,\n        d_model=cfg.d_model,\n        k=cfg.k,\n        auxk=cfg.auxk,\n        dead_steps_threshold=cfg.dead_toks_threshold // cfg.bs,\n        comms=comms,\n    ).cuda()\n\n    init_from_data_(ae, stats_acts_sample)\n\n    mse_scale = 1 / (stats_acts_sample.var(dim=0).mean()).item()\n    logger = Logger(project=cfg.wandb_project, name=cfg.wandb_name, config=cfg.__dict__)\n\n    # \u6062\u590d\u4e86AuxK\u7684\u635f\u5931\u51fd\u6570\n    def loss_fn(ae, flat_acts_train_batch, recons, info, logger):\n        # \u4e3bMSE\u635f\u5931\n        main_mse = (recons - flat_acts_train_batch).pow(2).mean()\n        logger.logkv(\"train_mse_unscaled\", main_mse)\n\n        # AuxK\u635f\u5931\n        auxk_loss = torch.tensor(0.0, device=main_mse.device)\n        if info[\"auxk_inds\"] is not None:\n            auxk_recons = ae.decode_sparse(info[\"auxk_inds\"], info[\"auxk_vals\"])\n            residual = (flat_acts_train_batch - recons).detach()\n            auxk_loss = normalized_mse(auxk_recons, residual)\n\n        logger.logkv(\"train_auxk_loss\", auxk_loss)\n\n        return main_mse * mse_scale + cfg.auxk_coef * auxk_loss\n\n    training_loop_(\n        ae,\n        batch_tensors(acts_iter, cfg.bs),\n        loss_fn,\n        lr=cfg.lr,\n        eps=cfg.eps,\n        clip_grad=cfg.clip_grad,\n        logger=logger,\n        comms=comms,\n    )\n\n    ### =======================================================================\n    ### \u65b0\u589e\uff1a\u8bad\u7ec3\u5b8c\u6210\u540e\u4fdd\u5b58\u6a21\u578b\u7684\u903b\u8f91\n    ### =======================================================================\n    print(\"\\n\" + \"=\"*50)\n    print(\"\u8bad\u7ec3\u5b8c\u6210\uff0c\u6b63\u5728\u4fdd\u5b58\u6a21\u578b...\")\n\n    # 1. \u521b\u5efa\u4fdd\u5b58\u76ee\u5f55 (\u5982\u679c\u4e0d\u5b58\u5728)\n    os.makedirs(cfg.save_dir, exist_ok=True)\n\n    # 2. \u786e\u5b9a\u6587\u4ef6\u540d\uff0c\u5982\u679c wandb_name \u672a\u8bbe\u7f6e\uff0c\u5219\u4f7f\u7528\u9ed8\u8ba4\u540d\u79f0\n    model_name = cfg.wandb_name if cfg.wandb_name else \"sae_model\"\n    save_path = os.path.join(cfg.save_dir, f\"{model_name}.pt\")\n\n    # 3. \u4fdd\u5b58\u6a21\u578b\u7684 state_dict\n    torch.save(ae.state_dict(), save_path)\n\n    print(f\"\u6a21\u578b\u5df2\u6210\u529f\u4fdd\u5b58\u5230: {save_path}\")\n    print(\"=\"*50)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></p> <p>\u63a5\u4e0b\u6765\u662f\u4ee3\u7801\u7684\u89e3\u6790\uff1a</p>"},{"location":"SAE/openai_sae_train/#mermaid","title":"\u8ba1\u7b97\u56fe (Mermaid)","text":""},{"location":"SAE/openai_sae_train/#_1","title":"\u6570\u5b66\u516c\u5f0f\u8be6\u89e3","text":""},{"location":"SAE/openai_sae_train/#_2","title":"\u524d\u5411\u4f20\u64ad\u516c\u5f0f","text":"<ol> <li>\u2461 \u4e2d\u5fc3\u5316\uff1a</li> </ol> <p>$$    \\text{E1: } \\mathbf{x}{\\text{centered}} = \\mathbf{x} - \\mathbf{b}    $$}</p> <ol> <li>\u2462 \u7f16\u7801\uff1a</li> </ol> <p>$$    \\text{E2: } \\mathbf{z}{\\text{pre}} = \\mathbf{W}}} \\mathbf{x{\\text{centered}} + \\mathbf{b}    $$}</p> <ol> <li>\u2463 Top-K \u7a00\u758f\u5316\uff1a</li> </ol> <p>$$    \\text{E3: } \\mathbf{z} = \\text{TopK}k(\\operatorname{ReLU}(\\mathbf{z}))    $$}</p> <ol> <li>\u2464 \u89e3\u7801\uff1a</li> </ol> <p>$$    \\text{E4: } \\mathbf{x}{\\text{partial}} = \\mathbf{W}    $$}} \\mathbf{z</p> <ol> <li>\u2465 \u6dfb\u52a0\u504f\u7f6e\uff1a</li> </ol> <p>$$    \\text{E5: } \\hat{\\mathbf{x}} = \\mathbf{x}{\\text{partial}} + \\mathbf{b}    $$}</p> <ol> <li>\u2466 \u4e3b\u635f\u5931\uff1a</li> </ol> <p>$$    \\text{E6: } \\mathcal{L}_{\\text{MSE}} = \\frac{1}{d} |\\hat{\\mathbf{x}} - \\mathbf{x}|^2_2    $$</p> <ol> <li>\u2467 \u7f29\u653e\uff1a</li> </ol> <p>$$    \\text{E7: } \\mathcal{L}{\\text{scaled}} = \\alpha \\cdot \\mathcal{L})    $$}} \\quad (\\alpha = \\text{mse_scale</p> <ol> <li>\u2468 AuxK \u7a00\u758f\u5316\uff1a</li> </ol> <p>$$    \\text{E8: } \\mathbf{z}{\\text{auxk}} = \\text{TopK}}}(\\operatorname{ReLU}(\\mathbf{z{\\text{pre}} \\odot \\mathbb{I}))    $$}</p> <ol> <li>\u2469 \u6b8b\u5dee\u8ba1\u7b97\uff1a</li> </ol> <p>$$    \\text{E9: } \\mathbf{r} = (\\mathbf{x} - \\hat{\\mathbf{x}}).\\text{detach()}    $$</p> <ol> <li> <p>\u246a \u8f85\u52a9\u89e3\u7801\uff1a</p> \\[ \\text{E10: } \\hat{\\mathbf{r}} = \\mathbf{W}_{\\text{dec}}[:, \\mathcal{I}] \\mathbf{v} \\quad (\\mathcal{I} = \\text{auxk\\_indices}) \\] </li> <li> <p>\u246b \u8f85\u52a9\u635f\u5931\uff1a</p> \\[ \\text{E11: } \\mathcal{L}_{\\text{AuxK}} = \\beta \\cdot \\frac{\\|\\hat{\\mathbf{r}} - \\mathbf{r}\\|^2_2}{\\|\\mathbf{r}\\|^2_2 + \\epsilon} \\quad (\\beta = \\text{auxk\\_coef}) \\] </li> <li> <p>\u246c \u603b\u635f\u5931\uff1a</p> \\[ \\text{E12: } \\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{scaled}} + \\mathcal{L}_{\\text{AuxK}} \\] </li> </ol>"},{"location":"SAE/openai_sae_train/#_3","title":"\u53cd\u5411\u4f20\u64ad\u516c\u5f0f","text":"<ol> <li>\u246d \u53cd\u5411\u4f20\u64ad\u8d77\u70b9\uff1a</li> </ol> <p>$$    \\nabla_{\\mathcal{L}_{\\text{total}}} = 1    $$</p> <ol> <li>\u246c \u603b\u635f\u5931\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\mathcal{L}{\\text{scaled}}} = 1, \\quad \\nabla = 1    $$}_{\\text{AuxK}}</p> <ol> <li>\u2467 \u7f29\u653e\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\mathcal{L}_{\\text{MSE}}} = \\alpha    $$</p> <ol> <li>\u2466 \u4e3b\u635f\u5931\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\hat{\\mathbf{x}}} = \\frac{2\\alpha}{d} (\\hat{\\mathbf{x}} - \\mathbf{x})    $$</p> <ol> <li>\u2465 \u6dfb\u52a0\u504f\u7f6e\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\mathbf{x}{\\text{partial}}} = \\nabla}}}, \\quad \\nabla_{\\mathbf{b{\\text{pre}}} = \\sum \\nabla    $$}}</p> <ol> <li>\u2464 \u89e3\u7801\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\mathbf{W}{\\text{dec}}^{\\text{(main)}}} = \\nabla{\\text{partial}}} \\mathbf{z}^\\top, \\quad \\nabla}} = \\mathbf{W{\\text{dec}}^\\top \\nabla    $$}_{\\text{partial}}</p> <ol> <li>\u246b \u8f85\u52a9\u635f\u5931\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\hat{\\mathbf{r}}} = \\frac{2\\beta}{|\\mathbf{r}|^2_2 + \\epsilon} (\\hat{\\mathbf{r}} - \\mathbf{r})    $$</p> <ol> <li>\u246a \u8f85\u52a9\u89e3\u7801\u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\mathbf{W}{\\text{dec}}^{\\text{(aux)}}}[:, j] =     \\begin{cases}     \\nabla \\    0 &amp; \\text{otherwise}    \\end{cases}    $$}}_i} v_j &amp; \\text{if } j \\in \\mathcal{I</p> <ol> <li>\u2463 Top-K \u68af\u5ea6\uff1a</li> </ol> <p>$$    \\nabla_{\\mathbf{z}{\\text{pre}, i}} =     \\begin{cases}     \\nablai} \\cdot \\mathbb{I}(z i \\in S_k \\    0 &amp; \\text{otherwise}    \\end{cases}    $$},i} &gt; 0) &amp; \\text{if </p> <ol> <li> <p>\u2462 \u7f16\u7801\u68af\u5ea6\uff1a</p> \\[ \\nabla_{\\mathbf{W}_{\\text{enc}}} = \\nabla_{\\mathbf{z}_{\\text{pre}}} \\mathbf{x}_{\\text{centered}}^\\top, \\quad  \\nabla_{\\mathbf{b}_{\\text{lat}}} = \\sum \\nabla_{\\mathbf{z}_{\\text{pre}}} \\] </li> <li> <p>\u2461 \u4e2d\u5fc3\u5316\u68af\u5ea6\uff1a</p> \\[ \\nabla_{\\mathbf{x}_{\\text{centered}}} = \\mathbf{W}_{\\text{enc}}^\\top \\nabla_{\\mathbf{z}_{\\text{pre}}} \\] </li> <li> <p>\u246e \u68af\u5ea6\u8c03\u6574\uff1a</p> \\[ \\nabla_{\\mathbf{W}_{\\text{dec}}}^{\\text{(adj)}} = \\nabla_{\\mathbf{W}_{\\text{dec}}} - \\text{diag}(\\mathbf{w}_j^\\top \\nabla_{\\mathbf{W}_{\\text{dec}}}) \\mathbf{W}_{\\text{dec}} \\] </li> <li> <p>\u2470 \u6743\u91cd\u5f52\u4e00\u5316\uff1a</p> \\[ \\mathbf{W}_{\\text{dec}}[:, j] \\leftarrow \\frac{\\mathbf{W}_{\\text{dec}}[:, j]}{\\|\\mathbf{W}_{\\text{dec}}[:, j]\\|_2} \\] </li> </ol>"},{"location":"SAE/openai_sae_train/#_4","title":"\u68af\u5ea6\u4f20\u64ad\u8def\u5f84\u7279\u6027","text":"<ol> <li> <p>\u4e3b\u8def\u5f84\u68af\u5ea6\u6d41\uff1a    <pre><code>\u246d \u2192 \u246c \u2192 \u2467 \u2192 \u2466 \u2192 \u2465 \u2192 \u2464 \u2192 \u2463 \u2192 \u2462 \u2192 \u2461\n</code></pre>    \u66f4\u65b0\u53c2\u6570\uff1a<code>W_enc, b_lat, b_pre, W_dec</code>\uff08\u4e3b\u6fc0\u6d3b\u5217\uff09</p> </li> <li> <p>\u8f85\u52a9\u8def\u5f84\u68af\u5ea6\u6d41\uff1a    <pre><code>\u246d \u2192 \u246c \u2192 \u246b \u2192 \u246a \u2192 \u2468 \u2192 \u2462 \u2192 \u2461\n</code></pre>    \u66f4\u65b0\u53c2\u6570\uff1a<code>W_enc, b_lat, b_pre, W_dec</code>\uff08\u8f85\u52a9\u6fc0\u6d3b\u5217\uff09</p> </li> <li> <p>\u68af\u5ea6\u5207\u65ad\u70b9\uff1a</p> </li> <li>\u6b8b\u5dee\u8ba1\u7b97 <code>r = (x - x_hat).detach()</code> \u963b\u6b62\u8f85\u52a9\u635f\u5931\u68af\u5ea6\u5f71\u54cd\u4e3b\u91cd\u6784\u8def\u5f84</li> <li> <p>\u786e\u4fdd\u8f85\u52a9\u8bad\u7ec3\u53ea\u6fc0\u6d3b\"\u6b7b\u4ea1\u795e\u7ecf\u5143\"\uff0c\u4e0d\u5e72\u6270\u4e3b\u7279\u5f81\u5b66\u4e60</p> </li> <li> <p>\u53c2\u6570\u66f4\u65b0\u8303\u56f4\uff1a</p> </li> </ol> \u53c2\u6570 \u4e3b\u8def\u5f84\u66f4\u65b0 \u8f85\u52a9\u8def\u5f84\u66f4\u65b0 <code>W_enc</code> \u2713 \u2713 <code>b_lat</code> \u2713 \u2713 <code>b_pre</code> \u2713 \u2713 <code>W_dec</code> TopK\u5217 AuxK\u5217 <ol> <li>\u68af\u5ea6\u8c03\u6574\u673a\u5236\uff1a    <pre><code># \u6b63\u4ea4\u6295\u5f71\u4f2a\u4ee3\u7801\nfor j in range(n_dirs):\n    w_j = W_dec[:, j]\n    g_j = grad_W_dec[:, j]\n    # \u6295\u5f71\u5230\u4e0ew_j\u6b63\u4ea4\u7684\u65b9\u5411\n    grad_W_dec[:, j] = g_j - torch.dot(g_j, w_j) * w_j\n</code></pre></li> </ol>"}]}